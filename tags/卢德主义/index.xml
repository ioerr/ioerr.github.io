<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>卢德主义 on 读写错误</title>
    <link>https://ioerr.github.io/tags/%E5%8D%A2%E5%BE%B7%E4%B8%BB%E4%B9%89/</link>
    <description>Recent content in 卢德主义 on 读写错误</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 08 Mar 2023 00:00:00 +0000</lastBuildDate>
    
      <atom:link href="https://ioerr.github.io/tags/%E5%8D%A2%E5%BE%B7%E4%B8%BB%E4%B9%89/index.xml" rel="self" type="application/rss+xml" />
    
    
      <item>
        <title>恐惧不是生存之道</title>
        <link>https://ioerr.github.io/posts/kongju-bushi-qiusheng-zhi-dao/</link>
        <pubDate>Wed, 08 Mar 2023 00:00:00 +0000</pubDate>
        <author>
            <name>Calon</name>
            <uri>https://twitter.com/calon</uri>
            <email>calon.xu@gmail.com</email>
        </author>
        <guid>https://ioerr.github.io/posts/kongju-bushi-qiusheng-zhi-dao/</guid>
        <description>&lt;p&gt;&lt;a href=&#34;https://twitter.com/tinyfool&#34;&gt;Tinyfool&lt;/a&gt; 和&lt;a href=&#34;https://www.bumingbai.net/&#34;&gt;不明白播客&lt;/a&gt;录制了一期《&lt;a href=&#34;https://www.bumingbai.net/2023/02/ep-037-tinyfool-text/&#34;&gt;ChatGPT 会如何改变我们的生活？&lt;/a&gt;》，结尾的核心观点是：科技不应该是被恐惧的东西，而是要被拥有的东西。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;我最近一直有在形成一个新的观点，就是技术呢，它的发展是不可阻挡的。基本上张三不发明，李四就发明；牛顿不做微积分，莱布尼茨也要做，甚至两个人一块儿做。那这些东西，它有它本质的关联。就是说当这个技术发明了，下一个技术可能就已经在路上了。但是问题出在哪儿呢？问题出在，我认为以前我们常用的话，“技术是双刃剑”是错的。问题出在技术不断在前进，而人也需要进化。人需要发展出新的理论去面对手里更厉害的武器。而不是去抱怨说这个东西怎么那么强大，它能不能用来害我？因为它的进步是无法阻挡，所以你就必须得去掌握它，你得让它变成一个好的东西。&lt;br /&gt;
我们今天看了很多科幻都是那种，比方说赛博朋克那种东西，它都是对未来宇宙很黑暗的理解，包括我们对核武器的理解都很灰暗。我认为这些想法都是对的，但是最终这些想法要回到怎么去提供一个方案，让我们既拥有了科技文明带来的好处，又去避免它有可能的坏处。今天对于ChatGPT我也是这么想的。这个AI，你想拿它去做一些垃圾内容，完全没问题，你想拿它去做一些坏事，完全没有问题。做坏事的人看到这个东西，他也是高兴得要命。但是你想让人们的生活变得更美好，你想让这个世界变革，也是需要这样的东西。&lt;br /&gt;
所以我很庆幸，包括有一句话，听着可能有些观众就不太喜欢了：我喜欢的这个社会，它应该不断地有科技进步，这样所有的文明都会想，我们应该开放应该包容，应该允许大家去创新。如果这个世界科技突然停止了，那OK了，那copy to China就赢了，因为你是静止的，那就看谁抄得快嘛。但是这个世界正好一步一步地证明，你抄得再快也没有用，因为世界在不停地在进步。所以我希望所有的各种进步不断地改变人类，希望人类去提升自己的文化能力，对世界的理解，我们去应对这个更牛逼的世界。不是说有一天AI、强AI出来以后，我们吓得四散奔逃，而是我们发现因为我们也变得非常伟大，而强AI只能是我们的朋友，只能辅助我们，这才是未来。我觉得科技不应该是被恐惧的东西，而是要被拥有的东西。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;有人问，对修改基因技术和克隆技术怎么看？&lt;/p&gt;

&lt;p&gt;我的观点是：&lt;br /&gt;
这些迟早会成为普及的技术，但如何让我们的伦理道德和社会制度适应、接纳，需要走很长一段路。&lt;br /&gt;
学界也知道靠堵是堵不住的，但观念的改变不是一朝一夕的事情，必然会有巨大的冲击震动。&lt;br /&gt;
这种适应和接纳不是一味的纵容，而是有配套的社会制度变化、伦理规范调整、心理转变。&lt;br /&gt;
奴隶制消亡、封建帝制终结、女性平权、同性恋婚姻等等都掀起了轩然大波，何况这种动摇生物基础和社会基本观念的变化，没个几百年不会消停。&lt;/p&gt;

&lt;p&gt;有人好奇，就算AI比人类推演强一万倍，谁有那个胆子真的把军队交给AI控制吗？&lt;br /&gt;
如果真能做到军队无人化，所有坦克飞机军舰甚至士兵都是AI控制的无人机，那么万一……AI一翻脸……？&lt;/p&gt;

&lt;p&gt;如果你的对手将部分武装交给AI管理，结果打得你屁滚尿流，你会不会学他？&lt;br /&gt;
如果到最后谁让AI介入越多谁就能赢，你说会不会都用上AI？&lt;br /&gt;
竞争这东西不是你想摆脱就摆脱的。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/Soulogic/status/1608499943408533504&#34;&gt;Soulogic&lt;/a&gt;：&lt;br /&gt;
杰克·伦敦身强力壮，一个人干了两个人的工，其中一个被他顶掉的工人后来自杀了&lt;br /&gt;
可能大家没想那么多、没那么邪恶，但这个话题在我这是个敏感的政治正确禁忌：&lt;br /&gt;
不要讨论在狮子面前如何跑得比别人快，不快跑的 loser 活该被吃。&lt;br /&gt;
作为角斗士我支持奴隶制，因为我能打赢&lt;/p&gt;

&lt;p&gt;全世界无产者，联合起来！&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;在我看来，这还是一种现代卢德主义。&lt;br /&gt;
竞争无处不在，技术进步干掉人工是不可阻挡的趋势，而且技术迭代的速度越快，被替代者适应的难度越高。&lt;br /&gt;
就像生物说“我不支持进化论”，不表示就能摆脱进化的规律。&lt;br /&gt;
&lt;a href=&#34;../zhishi-da-rongtong&#34;&gt;进步棘轮&lt;/a&gt;和红皇后效应避无可避。&lt;br /&gt;
能够做的是如何更合理地保护被替代的个体，平复阵痛，找到创新方向提升长远的竞争力。&lt;br /&gt;
人类文明发展到今天，早就在观念上跨过了失败者只能去死的阶段。&lt;/p&gt;
</description>
      </item>
    
      <item>
        <title>我为什么反对卢德主义</title>
        <link>https://ioerr.github.io/posts/wo-weishenme-fandui-luddism/</link>
        <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
        <author>
            <name>Calon</name>
            <uri>https://twitter.com/calon</uri>
            <email>calon.xu@gmail.com</email>
        </author>
        <guid>https://ioerr.github.io/posts/wo-weishenme-fandui-luddism/</guid>
        <description>&lt;p&gt;工业革命初期，失业的工人认为他们被机器抢走了工作机会，于是捣毁机器，他们被称为卢德主义者。&lt;/p&gt;

&lt;p&gt;随着工业革命继续进行，人们认识到机器取代低效的人力不可避免，卢德主义慢慢不再有号召力。&lt;/p&gt;

&lt;p&gt;到了计算机时代，新的卢德主义者们担忧计算机和人工智能会胜过和取代人类，许多科学家和计算机业界的知名人士也呼吁停止人工智能发展。&lt;/p&gt;

&lt;p&gt;我可以理解卢德主义者担忧技术快速发展带来的结构性失业问题，但不认为停止技术发展是解决该问题的好办法——无论从历史经验还是经济学理论来看，卢德主义都找错了问题的原因，表面看是技术带来的问题，归根结底还是经济和政治问题，其解决方案因此也站不住脚。&lt;/p&gt;

&lt;p&gt;我也认同未来的强人工智能的确有胜过、取代、奴役和消灭人类的危险，但从价值观出发，我强烈反感卢德主义——因为卢德主义代表最反对人类价值的观点。&lt;/p&gt;

&lt;p&gt;生命的价值和尊严在于生存本身，还是其创造的价值？&lt;br /&gt;
你是根据一个人生存状况还是他创造的东西来评价他？&lt;br /&gt;
这就是技术发展问题背后的价值观差异。&lt;/p&gt;

&lt;p&gt;在我看来，人类之所以为人类，区别于其他已知的生物，是因为人类会为了生存繁衍之上的理想和目标运用理性思考和技术工具，不断有目的、有意识地发明创造和改变世界，而不只是为了在残酷的环境中苟且偷生。&lt;/p&gt;

&lt;p&gt;如果人类没有超越世界给定的追求目标，那么无论生活如何富足舒适，和无智慧的生物又有什么本质区别？&lt;/p&gt;

&lt;p&gt;人工智能等计算机技术的发展，既是大幅度提升技术工具的生产力，也是对人类自身智慧机理的深入探索方式之一，更是突破自然界演化结果的尝试和挑战：突破碳基生命智慧上限，甚至与人工智慧并存形成新形态的生命形式。&lt;/p&gt;

&lt;p&gt;计算机时代的新卢德主义，则是在“人类的安全”和“人类成为更高维度智慧生命”之间，坚定认为为了前者的缘故，必须牺牲后者的机会——即使技术的发展未必就会毁灭人类，人类社会的问题也未必来自于技术发展，更不用说未来也许只有依靠新技术才能应对星球级别的天灾。&lt;/p&gt;

&lt;p&gt;曾经的地壳霸主恐龙统治地球表面超过1亿6千万年，人类站到食物链顶端的时间还差得远，但如果坚持卢德主义，失去技术发展带来的无限可能，那么人类的未来与恐龙将没有区别。&lt;/p&gt;

&lt;p&gt;另：最近看到冯象的《我是阿尔法》和阮一峰的《未来世界的幸存者》都表达了对机器取代人类的担忧，以及为了避免这种结局而停止技术发展的倾向。&lt;br /&gt;
这方面最值得说道的应该是 Kaczynski 的《工业社会及其未来》，事迹影响大，中文读者相对比较熟悉，一些对未来技术发展的思考可以引出不少有意思的话题，后续可以写个系列出来。&lt;/p&gt;
</description>
      </item>
    
  </channel>
</rss>
