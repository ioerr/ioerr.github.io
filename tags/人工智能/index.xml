<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>人工智能 on 读写错误</title>
    <link>https://ioerr.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/</link>
    <description>Recent content in 人工智能 on 读写错误</description>
    <generator>Hugo -- 0.126.0</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 26 Jan 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://ioerr.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>GFW的思维</title>
      <link>https://ioerr.github.io/posts/gfw-de-siwei/</link>
      <pubDate>Sun, 26 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/gfw-de-siwei/</guid>
      <description>Aristotle: It is not enough to win a war; it is more important to organize the peace. 对 TikTok 的禁令 从2020年至今，因为怀疑字节跳动公司的短视频分享平台 TikTok 违规泄漏用户敏感信息和威胁国家安全，美国</description>
      <content:encoded><![CDATA[<p>Aristotle:</p>
<blockquote>
<p>It is not enough to win a war; it is more important to organize the peace.</p>
</blockquote>
<h1 id="对-tiktok-的禁令">对 TikTok 的禁令</h1>
<p>从2020年至今，因为怀疑字节跳动公司的短视频分享平台 TikTok 违规泄漏用户敏感信息和威胁国家安全，美国政府对其采取了一系列措施：</p>
<p>2020年8月6日，时任总统特朗普签署13942号行政命令，认为 TikTok 收集了大量美国用户数据，可能被中国政府利用，对美国国家安全构成威胁。<br>
该命令依据《国际紧急经济权力法》（IEEPA），要求美国企业在45天内禁止与TikTok进行任何交易，并授权商务部进一步实施禁令。<br>
联邦法院认为政府超越了 IEEPA 赋予的权力，并且缺乏足够的事实依据，最终叫停。</p>
<p>2020年8月14日，特朗普政府要求字节跳动必须在90天内出售 TikTok，否则将封禁其业务。</p>
<p>2021年6月9日，拜登总统撤销了特朗普的禁令，同时指示商务部对外国应用程序的安全风险进行更全面的审查，以确定是否应采取新的监管措施。</p>
<p>2021至2022年，TikTok 提出“德克萨斯计划”（Project Texas），试图达成协议，符合安全监管要求，以避免禁令。<br>
计划内容包括：</p>
<ul>
<li>美国用户数据存储在美国，由 Oracle 托管（美国版“云上贵州”）</li>
<li>由第三方审查推荐算法</li>
<li>限制中国员工访问美国用户数据，内容审核透明公开</li>
</ul>
<p>美国政府认为这些措施不足以消除国家安全风险，理由是：</p>
<ul>
<li>推荐算法仍然在中国开发和维护，无法彻底切断与字节跳动和中国政府的联系</li>
<li>没有有效机制能够确保中国政府不会访问美国用户数据</li>
<li>无法有效监管用户数据的传输</li>
</ul>
<p>2023年2月27日，美国政府要求其下所有政府机构移除设备上的 TikTok 应用。</p>
<p>2023年3月，美国外国投资委员会（CFIUS）正式要求字节跳动完全剥离 TikTok 的美国业务，否则可能会面临全面封禁。<br>
TikTok 认为“德克萨斯计划”已经足够保护美国用户数据。如果必须出售，它宁愿选择退出美国市场。</p>
<p>2024年3月7日至4月24日，美国参众两院通过《保护美国人免受外国对手控制应用程序侵害法案》（Protecting Americans from Foreign Adversary Controlled Applications Act）并由时任总统拜登签署。<br>
法案将 TikTok 归类为“外国对手控制的应用程序”，并规定：</p>
<ul>
<li>TikTok 需要在270天内完成剥离字节跳动的所有权，否则禁止其在应用程序商店上架，美国企业也不得为其提供网络托管服务</li>
<li>TikTok 不能与字节跳动有任何形式的运营关系，包括算法共享或数据交换</li>
<li>如果剥离有实质进展，总统可以给予最多90天的延期</li>
</ul>
<p>TikTok 及其用户团体提起诉讼，认为该法案违反第一修正案，限制了美国用户的言论自由。<br>
2024年12月6日，美国哥伦比亚特区巡回上诉法院驳回 TikTok 对美国政府提出的诉讼案，认为禁令法案不违反美国宪法第一修正案所保护的言论自由。<br>
2025年1月17日，美国最高法院裁定支持禁令。<br>
其后，字节跳动一度终止了 TikTok 对美国用户的服务，因为美国当选总统特朗普的认可，目前又恢复了服务。</p>
<h1 id="美国最高法院的理由">美国最高法院的理由</h1>
<p><a href="https://www.supremecourt.gov/opinions/24pdf/24-656_ca7d.pdf">最高法院认为</a>，对 Tiktok 的禁令没有违反美国宪法第一修正案对言论自由保护的理由如下：</p>
<ol>
<li>
<p>事关国家安全利益：<br>
字节跳动受中国法律约束，可能被迫向中国政府提供用户数据。法案的核心目的是防止中国政府利用 TikTok 收集美国用户的数据，威胁国家安全。</p>
</li>
<li>
<p>内容中立：<br>
该法案并未针对 TikTok 上的具体内容或言论，而是针对外国对手对该应用的控制，因此最高法院认为不属于内容审查。</p>
</li>
<li>
<p>TikTok 有其特殊之处：<br>
数字信息的收集和分析虽然是互联网公司的常见做法，但因为 TikTok 用户规模巨大，且母公司受外国对手政府管辖，所以最高法院认可施加额外监管措施是合理且必要的。</p>
</li>
<li>
<p>信任国会和政府的判断：<br>
在涉及国家安全问题时，法院通常会给予国会和行政部门更大的自由裁量权，因为国家安全事务往往涉及更专业和复杂的信息，面对更高的风险，有时可能要基于不确定的信息来做出合理的推断。<br>
TikTok 声称中国政府不大可能会强迫它提交用户数据用于情报收集目的，因为中国有更有效和高效的获取相关信息的手段，但鉴于中国政府过去有广泛的数据收集和间谍行为记录，最高法院认为，即使尚未有其利用与字节跳动的关系访问美国用户的确凿数据，美国政府对 TikTok 数据安全风险的评估也是合理的，国会有充分理由采取立法行动。</p>
</li>
<li>
<p>符合中度审查要求<br>
最高法院认为，由于大多数情况下，内容中立的法律对排除某些思想或观点进入公共对话的风险较小，因此受到中等程度的审查。<br>
<a href="https://en.wikipedia.org/wiki/Intermediate_scrutiny">中度审查（Intermediate Level of Scrutiny）</a>在美国宪法审查中介于合理审查（Rational Basis Review）和严格审查（Strict Scrutiny）之间，其标准如下：</p>
</li>
</ol>
<ul>
<li>限制是否在政府的宪法权力范围内</li>
<li>限制是否促进重要实质的政府利益</li>
<li>政府利益是否与压制言论自由无关</li>
<li>该限制是否具有针对性、是否必要</li>
<li>该限制是否保留了充分的交流机会</li>
</ul>
<p>而判决认为该法案没有根据言论的内容、功能和目的实施禁令，也没有直接限制表达观点的内容创作者，促进的国家安全利益与压制言论自由无关，没有不必要地限制更多言论，因此没有违宪。</p>
<ol start="6">
<li>没有其他替代方案<br>
最高法院认可，国会已经花费多年时间与 TikTok 进行谈判，数据共享限制、披露要求等替代方案无法有效解决安全问题，最终只有剥离字节跳动对 Tiktok 的控制权才能有效保护美国用户的数据和国家安全。</li>
</ol>
<h1 id="对禁令的看法">对禁令的看法</h1>
<p>从最高法院列举的理由来看，主要的依据就是：</p>
<ol>
<li>事关国家安全，对应理由1-6点</li>
<li>没有针对特定的言论和观点，对应理由2、5点</li>
</ol>
<p>如果是国家安全的理由，那么政府和国会必须证明，禁令是防止严重伤害国家安全且迫在眉睫的唯一方法，因此才有必要强制企业交出控制权，以及强迫用户放弃使用正当使用特定服务的权利。<br>
但政府和国会既没有指出 Tiktok 对国家安全造成实际或迫在眉睫的危害——一切都还只是推断和没有找到实际证据的怀疑——哪怕它确实极有可能为真（不要装外宾）；也没有解释 TikTok 的数据收集行为与其他无数公司有何不同——唯一的不同就是它属于中国管辖而其他收集、利用用户数据的公司很多属于美国管辖，反而显得“保护美国用户数据”特别可笑；更没有证明这是唯一可能有效的方法——美国至今没有与欧盟的《<a href="https://en.wikipedia.org/wiki/General_Data_Protection_Regulation">通用数据保护条例（GDPR）</a>》等效的联邦法案，也没有在长达4年的时间里掌握任何 Tiktok 收集数据并交给中国政府利用的实质性证据，如果这次的禁令就是最后手段，那更像是黔驴技穷。<br>
后果就是将国家安全凌驾于公民个人权利之上的风险进一步扩大。</p>
<p>而在这种情况下，是否针对特定的言论和观点就没那么重要了，因为国家权力已经习得了扩张权力和提升权限的捷径，拿到了所需的枪支弹药，是众生平等地扫射还是有的放矢地狙击，有多大区别呢？</p>
<p>所谓“危害国家安全”，并非就等于危害“国家”这一实体的“安全”。<br>
因为“国家”由无数个人组成，它不是实在的主体，公民安全的综合才叫“国家安全”。<br>
而对公民个人安全的伤害，既可能来自于万里之外危及公民生命、财产的敌人，也可能来自于近在咫尺、肆意妄为的暴政，不是只有来自外国的伤害才叫做伤害，这应该是很容易理解的政治学常识。<br>
为了防范和阻止伤害公民安全，而增加政府伤害公民的权力，对被伤害的公民来说，两者并无本质区别，如果前者叫做“危害国家安全”，那么后者也是。</p>
<p>国家政府可以无需证据、仅凭怀疑而禁止和惩罚任何可能的对手和敌人吗？<br>
其实是可以的，因为法律的更新总是落后于实际，公民有可能为了保护自身安全而授予政府一定的自由裁量权力，在不同的国家和不同的环境下，这一自由裁量的范围可以相差很大，大到政府可能凭此权力剥夺公民的基本自由。<br>
同时，公民也有责任判断这种权力是否过度，并发起收回授权的流程——如果有法定流程的话，或者讨论明确什么是“国家安全”和应该授予何种权力，以及在不可收拾之时反抗、推翻挣脱约束、独断专行的政府。<br>
这种安全没有人可以代替自己来分辨，唯有自己为自己的选择承担后果。</p>
<p>任何公民都可以依据自己的认知做出判断，每个人的认知水平、已知信息和对自身利益、威胁的评价各不相同，所谓“国家安全”不是公民必须接受和服从政府禁令的理由。</p>
<p>在 TikTok 停止服务期间，许多美国用户涌入其他替代应用，比如“小红书”（其实绝对数量和比例并没有多高，只是很有话题），并且声称不在乎自己的数据被中国的互联网服务和政府收集、使用。<br>
虽然显得很愚蠢，但也凸显这一禁令的荒唐。不妨设想一下，既然事关美国国家安全，那么如果原有 TikTok 的美国公民用户主动注册、使用小红书或其他中国应用并提供自己的用户信息，是否集体犯下叛国罪？<br>
为了确保美国国家安全不受进一步的威胁，阻止美国用户使用中国的互联网服务，政府和国会是否要批准建立向 GFW 看齐的防火墙？</p>
<h1 id="deepseek-的突然爆红">DeepSeek 的突然爆红</h1>
<p>2025年1月20日， 对冲基金幻方量化创立的人工智能与大模型公司 DeepSeek 发布并开源了 DeepSeek-R1 推理模型，可以以更低成本实现与 OpenAI 公司 o1闭源模型相当的性能和效果。<br>
一时间 DeepSeek 成为焦点，并导致为人工智能行业提供大量高性能显卡的英伟达公司股价一度大跌。而且到现在为止，DeepSeek 因为使用量太大，不堪重负，服务的稳定已经收到严重影响，还暂停了 API 服务的付费入口。<br>
同时，DeepSeek 的成功也引起了不少争议，比如 OpenAI 认为 DeepSeek 使用知识蒸馏技术复制其模型进行开发，违反了 OpenAI 的服务条款。</p>
<h1 id="关于封禁服务的讨论">关于封禁服务的讨论</h1>
<p>看到<a href="https://x.com/boiledwater/status/1883445957192503665">推友 Jess 说</a>：</p>
<blockquote>
<p>TikTok刚火时，欧美都无所谓。多年后才发现它的毒性，想禁，却极为困难。</p>
<p>而一个由极权体制主导的超级人工智能必然不会服务于人，而是服务于极权体制。它会强化对社会的全面控制，包括思想、信息和行为，润物细无声。</p>
<p>TikTok负责娱乐，DeepSeek负责学习。全世界的年轻人，将在潜移默化中被彻底掌控。</p>
</blockquote>
<p>联想到之前 TikTok 的禁令，这样的观点应该是支持再禁 DeepSeek，于是我<a href="https://x.com/calon/status/1883465122976551232">回复</a>：</p>
<p>禁了 TikTok，又要再禁 DeepSeek？<br>
我是不赞同这样的，这和 GFW 的思维逻辑很接近了。<br>
如果极权体制的产物在思想市场中永远占优势，那么靠封禁是挡不住的，而如果其并无优势，那么不需要封禁手段。<br>
自认为站在极权体制对立面的人，思想僵化，创造力贫乏，文化枯竭，失去了竞争优势，是更大的问题。</p>
<p><a href="https://x.com/boiledwater/status/1883582572531417191">Jess 则认为</a>，这和禁地沟油、处罚混用工业用油的食用油运输油罐车类似。<br>
互联网和水与食物一样，是生存必需品，是基本人权。<br>
被人为混了毒，必须治。</p>
<p>我觉得其中值得深入辨析的点比较多，Twitter 上不适合沟通，就在这里继续说吧。</p>
<h2 id="民众需要禁令吗">民众需要禁令吗？</h2>
<p>禁地沟油是因为，食用油的质量标准分明，从成分到工艺都有要求，商家已经在事实上违约违法，同时，消费者没有技术能力也承担不起成本自行检验，因此无法在消费时辨别、拒绝使用地沟油，才需第三方介入进行质量检验和处罚。否则，消费者不需要禁就能自己做选择，或者发起集体诉讼。<br>
短视频和 AI 的用户则很清楚自己需要和不在乎什么。若认为其帮助极权者影响思想、控制行为，应该帮助用户认识到有毒并尊重其选择，而非替用户封禁。</p>
<p>认为民众愚蠢无知，无运用理性和自律负责能力，不知道后果严重，更会影响高尚和正义的事业，或者说，不相信人有在受控环境从复杂信息中运用理性能力突破限制的能力，必须由一个智慧英明的第三方来控制管理和“启蒙”，比如部落领袖、皇帝国王、宗教头目、政府元首和知识分子哲人王先知，这是 GFW 思维的第一个方面。</p>
<h2 id="封杀的标准是什么">封杀的标准是什么？</h2>
<p>世界上最简单的论断莫过于：我代表真理正义而对方邪恶。<br>
说要消灭邪恶很简单，但什么算邪恶，有多邪恶，该如何面对，并非不言自明。<br>
有魔怔人还认为中国人全是邪恶帮凶统统该死呢。<br>
开源 AI 模型要封杀的标准是什么？依此标准，哪些服务也要封杀？法理依据是什么？需要详细阐明而非一句简单论断就能代替。</p>
<p>不相信公开、理性和逻辑明白的论证可以得到他人的认同，利益此消彼长会让人变换立场，更相信人的观念只有靠强制才会改变，因此任意独断、不公开的强制权力总是比沟通和交换更加有效，是 GFW 思维的第二个方面。</p>
<h2 id="封杀是仅剩的手段吗">封杀是仅剩的手段吗？</h2>
<p>AI 模型市场竞争激烈你追我赶，一时领先不奇怪。市场竞争用市场手段，如果违法违规有法律手段。如果动用公权力封杀，那只能说明市场和法律框架内应对不了“极权体制主导的 AI”（怎么就成了极权体制代表产物，也得先给个令人信服的论证），这相当于承认极权更适合发展 AI 吧，现在下此结论是不是太早了。</p>
<p>若真如此，那下一步是不是该不惜牺牲生产力、违背市场需求也要封杀 AI？继续就到卢德主义或者“宁要自由民主的草，不要专制极权的苗”了，相当于将坚持的意识形态放在了人性的对立面，只能依靠隔绝来维持其脆弱的一面不被攻破。</p>
<p>希望用封杀来阻止更顺应人性的事物，是 GFW 思维的第三个方面。</p>
<h2 id="不同意封杀的人都是帮凶吗">不同意封杀的人都是帮凶吗？</h2>
<p>我觉得第一反应要封杀 DeepSeek 更像是被恐惧所裹挟，恐惧来自于将 DeepSeek 与 AI 突飞猛进、极权体制关联起来的叙事，这和认为强人工智能的奇点近在咫尺，应该马上封杀和停止所有 AI 研究的心态类似。<br>
网友认为我天真幼稚，愚钝短视，不能理解其中的利害关系，都很正常，但“自由民主”的真义就是每个人都允许保留自己的观点。<br>
网络上的讨论毕竟短浅，大可以继续争论生产力是不是代表一切，顺应人性的也可能是毒品和色情，历史上有独断专行的强力控制带来良好结果的例子，走正当法律程序封杀就与 GFW 不一样了，等等。</p>
<p>而类似的讨论中总有人像狂躁症发作一样，将封杀视为唯一可行的防范手段，凡是不认可这一手段的必要性的人都是邪恶的帮凶，喊打喊杀喊要屠光，也算是网络上的常见精神疾病症状了。</p>
<p>将网络争论中的不同观点当作识别敌我的条件，然后顺理成章认为对敌人可以采取任何恶意手段——听上去是多么熟悉的“革命”手段，在我看来这相当于认可言论定罪的原则，自行蜕变或希望培育他人成为意识形态寄生僵尸，这是网络上非黑即白地浅薄对立背后隐藏的 GFW 思维的第四个方面。</p>
<p>2025-02-16 更新：</p>
<p>如果非要做类比，用毒品比地沟油更好。<br>
毒品会毁掉身心健康，凭借个人理性和自制力无法对抗，由于利益驱动，在社会层面也难以禁绝其传播。</p>
<p>但是，一方面短视频应用是否像毒品一样个人无法对抗，目前尚无定论，毕竟身边正常生活没有被短视频应用影响到的人比比皆是。曾经被视为洪水猛兽，扣上“电子鸦片”、“电子海洛因”罪名的电子游戏，也早已在社会中普及，天没有塌下来。</p>
<p>另一方面，一些类似毒品成瘾的案例，其消费的内容与是否是极权国家生产制造无关，任何迎合、奖励和刺激原始本能的内容，都可能导致一些人成瘾。</p>
<p>如果需要以类似毒品的理由来禁短视频应用，那么应该禁的是所有应用而不仅仅是 TikTok，而如果理由是个人无法抵挡极权主义的思想毒素，那么需要论证思想本身就是受人欢迎、无法阻断的病毒，自带无法抵挡的复制能力，不能与作为传播手段的短视频应用的传播能力混为一谈。</p>
<p>2025-02-22 更新：</p>
<p>如果极权主义的思想有如此大的魅力，竟可以冲破理性的防御，要么说明它符合原始人性本能，要么是符合当下思想市场的需求。</p>
<p>如果是前者，这说明理性启蒙理想的失败，就好像毒品证明了人的生物本能和自律的神话在化学制品面前不堪一击。<br>
理想无法违背人性本能的现实独立存在，如果只能用强制隔离戒断的方式来阻止人性本能，那么在思想市场上的强制隔离戒断本身就违背了理想。</p>
<p>如果是后者，这说明理性启蒙运动的失败。<br>
当下不缺少知识分子居高临下“启蒙”、“指导”和“教化”的意愿和傲慢态度，另一方面，也充斥着“黄金时代”末期民众对自由、民主、平等、进步、全球化等启蒙时代产物及其经济、政治、军事、文化领域衍生物的普遍失望。“历史终结”的宣称早就是笑话，只是很多人还假装继续相信，浑然不觉现在经历的是重新评估一切。</p>
<p>在民众看来，理性启蒙的整套解决方案已成根基空虚的无本之木。因为太多人说只需知其然而不必知其所以然，它从哪里而来，为什么而生，能解决什么疑惑和问题，是否仍有必要，未来向何处去，无需理解和关心。遇到一切实际问题，只需要坚定信仰、默念已经成为常识的信条就能找到答案。<br>
但每天一睁开眼，问题仍然在那里。</p>
<p>于是有的人不能理解，有的人普遍怀疑，有的心存抗拒，有的冷漠面对，有的则视自由平等为唾手可得的理所当然和不值得珍惜的廉价套餐。如果有终极答案当然很好，特别是按下一个万能的按钮就可以实现，如果有其他人替我按按钮就更棒了，如果没有似乎也不是大不了的事情，现状不会更糟糕。</p>
<p>这时，如果一个新版本终极答案出现，不仅对自由、民主、平等、公正等概念有“全新版本”的理解，而且许诺只需要放弃一点个人获得信息、思考、评价、判断、发言和选择的权利——反正一般人有限的智识水平不顶用，连自己的利益和偏好都不清楚，还操心什么理性自我启蒙呢——万事万物交给更加“专业、客观、公平、一致、值得完全信赖”的“超级智能”统一指挥，不但能解决眼前的实际问题，还能复兴过去的伟大、动员现在的力量、创造未来的辉煌、促成整体的幸福…岂不美哉？对比令人一再失望的现状，有多少人会心动呢？</p>
<p>如果将极权主义看作思想毒品，从理性启蒙时代一路演进至此的现代社会被虚无主义侵蚀根基才是毒品无法抗拒的原因。靠封杀解决不了越来越高涨的对极权主义及各种变体的需求问题。</p>
<p>这让我想到了在<a href="https://x.com/horsezhanbin/status/1888070727770980599">另一个会话</a>中回复<a href="https://x.com/horsezhanbin">马老师</a>的<a href="https://x.com/calon/status/1888082194951791014">观点</a>：<br>
在这个迈向混乱的时代，披着标新立异的皮但实际上干着死灰复燃的事太多，怀疑一切和拥抱虚无的人太多，回到坚实的起点尝试重新建构和塑造的太少。</p>
]]></content:encoded>
    </item>
    <item>
      <title>算哪根葱？</title>
      <link>https://ioerr.github.io/posts/suan-nagen-cong/</link>
      <pubDate>Sat, 26 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/suan-nagen-cong/</guid>
      <description>James Cameron： 通用人工智能不是从民主政府的资助中诞生，而是从目前正在投入数十亿甚至百亿美金研究开发的商业科技巨头中产生。 因此，大家将生活</description>
      <content:encoded><![CDATA[<p>James Cameron：</p>
<blockquote>
<p>通用人工智能不是从民主政府的资助中诞生，而是从目前正在投入数十亿甚至百亿美金研究开发的商业科技巨头中产生。<br>
因此，大家将生活在一个没有你同意没有投票选择的世界里，人们将与一个超级智能的“外星物种”共同生活，而这个物种服从的是企业的目标和规则。<br>
这个实体可以访问你的通讯记录、信仰、你曾经说过的一切，以及通过个人数据获取每个人的位置信息。<br>
所以，现实资本主义很快就能转变成数字极权主义。<br>
最好的情况是，这些科技巨头会变成自封的人类利益仲裁者。<br>
但这就好比让狐狸看守鸡舍，永远希望他们永远不会想到利用这种权力来对付我们，榨干我们最后一滴血汗。<br>
这比我40年在《终结者》呈现的更可怕。<br>
原因无它，仅仅是因为这不再是科幻片，而是正在发生。</p>
</blockquote>
<p>极权主义和奴隶制度都早有人甘之如饴，数字极权主义和现实资本主义算哪根葱啊。</p>
]]></content:encoded>
    </item>
    <item>
      <title>杞人忧天</title>
      <link>https://ioerr.github.io/posts/qiren-youtian/</link>
      <pubDate>Sun, 29 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/qiren-youtian/</guid>
      <description>ZoomQuiet： AI 安全和以往最大的不同在, 这种安全留给人类反应的时间越来越短, 不像 DDT 时代,我们用20年发现有问题, 用10年修正, 整个儿生</description>
      <content:encoded><![CDATA[<p><a href="https://x.com/zoomq/status/1840237734071607371">ZoomQuiet</a>：<br>
AI 安全和以往最大的不同在,<br>
这种安全留给人类反应的时间越来越短,<br>
不像 DDT 时代,我们用20年发现有问题, 用10年修正,<br>
整个儿生态并没崩溃;<br>
而 AI 的安全问题可能, 几百亳秒后, 超级智能诞生,<br>
因为最初一行道德代码中一个标点错误,<br>
人类就消失了,我们一点儿改善/修订的机会都没有&hellip;</p>
<p><a href="https://x.com/calon/status/1840252252650623154">Calon</a>：<br>
我目前仍然觉得这是杞人忧天。<br>
超级智能诞生，和超级智能能够认识、理解、改造和掌握现实世界，中间还有巨大的鸿沟。</p>
<p>对超级智能的担忧某种程度上是人类对自身能力自负的投射和放大。<br>
虽然人类会认为自己的智能会赶不上超级人工智能，看上去是谦虚、自卑，但实际上也可能是认为自己凭借智能优势已经成为万物之灵、世界的主宰。<br>
如果出现一个比自己更智慧的存在，那可不得了，一定会是新的霸主，而且会无法克服并继承和放大自己的贪婪、残忍、极端…这个新的霸主一定能够凭借智慧突破认知瓶颈，无往而不利，直接飞升成仙都不为过。</p>
<p>人类以为自己在这个境界的临门处徘徊着，只要超越自己就行了。<br>
也许实际上还差得远呢——即使是超越了人类的超级智能，也只是鸭立鸡群的程度而已。</p>
]]></content:encoded>
    </item>
    <item>
      <title>硅基智能的分裂</title>
      <link>https://ioerr.github.io/posts/guiji-zhineng-de-fenlie/</link>
      <pubDate>Mon, 24 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/guiji-zhineng-de-fenlie/</guid>
      <description>未来硅基智能也许会分裂成两派： 一类是人工智能（Artificial Intelligence），即人类从自己的角度出发理解世界而设计出的智能。</description>
      <content:encoded><![CDATA[<p>未来硅基智能也许会分裂成两派：</p>
<p>一类是人工智能（Artificial Intelligence），即人类从自己的角度出发理解世界而设计出的智能。其感知的方式、思维的方式、学习的经验、探索的问题，都带有浓浓的人类色彩；<br>
另一类是非人工智能（Non-Artificial (Self-Originated) Intelligence），即完全脱离人类演进路线而产生的智能。一切都是为了求解硅基生命自己独有的问题，追寻自身与人无关的目的而存在。</p>
]]></content:encoded>
    </item>
    <item>
      <title>对《生成式人工智能服务管理办法》的意见和建议</title>
      <link>https://ioerr.github.io/posts/dui-shengchengshi-rengong-zhineng-fuwu-guanli-banfa-de-yijian-he-jianyi/</link>
      <pubDate>Tue, 11 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/dui-shengchengshi-rengong-zhineng-fuwu-guanli-banfa-de-yijian-he-jianyi/</guid>
      <description>国家互联网信息办公室发布了《生成式人工智能服务管理办法（征求意见稿）》，向社会公开征求意见。 花了点时间匆匆提交了一些不成体系的意见和建议，其</description>
      <content:encoded><![CDATA[<p>国家互联网信息办公室发布了《<a href="http://www.cac.gov.cn/2023-04/11/c_1682854275475410.htm">生成式人工智能服务管理办法（征求意见稿）</a>》，向社会公开征求意见。<br>
花了点时间匆匆提交了一些不成体系的意见和建议，其实也知道不会起什么作用，而且问题的症结也不在某个行政部门，只是想表达观点，顺便吐槽。</p>
<p>不合理的条款会严重打击和影响我国人工智能领域创新的积极性，对中小企业的影响尤为严重，管理办法征求意见稿刚一发出，网络上就已经一片批评意见，在此AI技术发展和应用的关键节点，希望管理部门能够以更加包容、开放、服务、法治的管理意识为我国的人工智能领域发展保驾护航。</p>
<p>针对管理办法的意见和建议主要有以下几个方面：</p>
<ul>
<li>取消没有实际意义和多此一举的条款</li>
<li>取消实际会影响技术发展和推广应用的条款</li>
<li>取消增加服务者不合理责任的条款</li>
<li>取消或修改违背法治精神的条款</li>
<li>明确或取消执行标准模糊的条款</li>
</ul>
<p>具体如下：</p>
<ol>
<li>第三条“国家支持人工智能算法、框架等基础技术的自主创新、推广应用、国际合作，鼓励优先采用安全可信的软件、工具、计算和数据资源”是没有实际意义的表态，且与后续条款实际效果不一致，建议取消；（我当然知道这种空话套话随处可见，什么时候可以彻底消灭掉呢？）</li>
<li>多个条款中“不得含有”、“采取措施防止出现”和“生成”、“保证数据的真实性、准确性、客观性、多样性”、“内容过滤”、“防止再次生成”、“对生成的内容进行标识”等的要求，不符合生成式人工智能的技术原理，实际执行只会导致打击而非鼓励自主创新、推广应用、国际合作的积极性，与第三条的精神冲突；</li>
<li>第十条“采取适当措施防范用户过分依赖或沉迷生成内容”，此处过分依赖和沉迷的标准不明确，建议明确或取消；</li>
<li>第十一条“不得根据用户输入信息和使用情况进行画像”，不应禁止互联网服务的用户画像行为，这是提升用户感知和服务质量的必要手段，应与不能推断个人身份相结合来确保用户隐私，无需对画像专门禁止；</li>
<li>第十三条“提供者应当建立用户投诉接收处理机制”，投诉处理机制应由服务提供者自由决定是否提供，同时，涉及滥用、侵权行为的，不应由投诉处理机制承接，而应完善相应法律法规，通过法律途径解决；</li>
<li>第十四条“提供者应当在生命周期内，提供安全、稳健、持续的服务，保障用户正常使用”属于企业自负其责的生产经营策略，不需要管理办法规定，建议取消；</li>
<li>第十七条“提供者应当根据国家网信部门和有关主管部门的要求，提供可以影响用户信任、选择的必要信息”，建议进一步明确要求的主体部门和信息的范围、标准，方便执行；进一步地，建议经过认证后统一披露，向消费者推荐，而非强制要求提供；</li>
<li>第十八、十九条应由用户承担相应法律责任，而不应由服务方承担责任，且应避免鼓励向网信部门或者有关主管部门举报的条款，如果服务方和利用服务的用户的违法行为损害他人正当权益，应由被害人针对责任人提起法律诉讼，而不应鼓励第三方举报；管理部门应降低通过法律诉讼维护正当权益的成本；</li>
<li>第二十条“法律、行政法规没有规定的，…”，属于通过行政管理部门行政管理办法扩大法外处罚范围，无论是终止服务还是罚款，都可能因为滥用而影响企业正常生产经营，也违背法治精神，建议取消，或改为通过人大审议后立法。（我当然也知道人大立法不过是走个过场，但总还是比依赖行政处罚的手段强）</li>
</ol>
<p>其实还想提意见说施加在企业身上的不合理责任越多，越不利于中小企业的创新，是增加大企业不正当竞争和固化市场垄断的因素之一，但估计管理部门既不关心也不理解。</p>
]]></content:encoded>
    </item>
    <item>
      <title>人还有价值吗？</title>
      <link>https://ioerr.github.io/posts/ren-haiyou-jiazhi-ma/</link>
      <pubDate>Thu, 06 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/ren-haiyou-jiazhi-ma/</guid>
      <description>《不合时宜》播客最近发布了一期《AI狂飙的时代，人类还有价值吗？》的节目，嘉宾木遥和主播王磬展开了关于 ChatGPT 和人工智能的讨论。 链接中有节目的全文</description>
      <content:encoded><![CDATA[<p>《不合时宜》播客最近发布了一期《<a href="https://mp.weixin.qq.com/s?__biz=MzIzOTc1OTQ3OQ==&amp;mid=2247486162&amp;idx=1&amp;sn=826f991907db55decfbefff7315f3c55">AI狂飙的时代，人类还有价值吗？</a>》的节目，嘉宾木遥和主播王磬展开了关于 ChatGPT 和人工智能的讨论。</p>
<p>链接中有节目的全文内容，还是挺长的，但我觉得非常值得一读。</p>
<p>没有借助 AI，我自己的总结归纳如下：</p>
<p>ChatGPT 从3.0到3.5之间，建立了因果链条能力，可以做一些推断性的事。</p>
<p>人的思考有快和慢两种模式。<br>
快模式不经过思考，依赖于生物本能，传统意义上的神经网络模仿的是人的快思考；<br>
慢模式要一步一步想问题，有一大堆中间步骤（简化了表述，建议读卡尼曼的原著），思维链条（COT）在模仿人类的慢思考，把一堆信息综合在一起，推出一堆中间结果，最终得到结论。<br>
之前的 AI 都是专业领域训练和应用，ChatGPT 让人看到了通用人工智能模型的曙光。</p>
<p>AI 在人的生活中的渗透是一个逐渐的过程，不会一下子完全取代，而是逐步冲击并且已经在发生。<br>
GPT 的本质是一种以对话为界面的服务，帮助获取信息，一切以对话为服务形式的工作都会被改变。<br>
ChatGPT 虽然现在有缺陷，如不够精准，使用封闭模型，可以通过改进模型和与其他检索服务结合来迅速提升。</p>
<p>进入工业革命以来，人类认为智力劳动比体力劳动更有价值，因为机器能够在体力上胜过人类，却做不到从智力上超越人类。<br>
假如 AI 在智力上也碾压人类，人类的价值和存在意义都可能被推翻。<br>
现在带来优势社会地位的劳动分工，在被 AI 冲击后，可能变为弱势分工。<br>
传统上认为女性更擅长的很多优势可能会更加重要。<br>
可能只有人和人交流的意义上所付出的劳动无法被取代。<br>
甚至人与人的情感关系会被人与 AI 的情感关系取代。</p>
<p>现代的人有其时代局限性和固有惯性，会有太多的未知新生事物，站在现代根本无法预料到未来会如何，可能需要一两代人才能进入新时代。<br>
要多关注一线的 AI 研究人员的信息而不是业界已经功成名就的人，后者知识更新更慢，或者受成见影响。</p>
<p>AI 的多样性和差异会远远大于人类之间。<br>
AI 也会极大地放大人和人之间技能差异所带来的资源差异，会让极少数控制AI、掌握AI的人创造价值和调动资源的能力远超一般人。<br>
社会不平等会进一步放大，与失去存在意义相结合，可能造成整个社会不稳定。</p>
<p>不了解事情的本质，凭着恐慌或者焦虑来做监管，会扼杀和阻碍创新，或者没有任何意义。<br>
面对 AI 的冲击，安全保障和保持灵活性留有多个选项很重要，主动迎接变化，才能避免安全感缺失的焦虑。</p>
<p>AI 有能力联系已有的想法进行创新，部分创新工作也能替代人工。<br>
从无到有完全原创性的创新可能不会被 AI 替代，但这只是个安慰，对大部分人没有意义。<br>
要锻炼自己影响人的能力、沟通能力、团队组织能力。</p>
<p>需要深入思考的问题：<br>
如果人生观被推翻，如何重塑？<br>
即使工作被 AI 取代，什么能让你觉得生存于世是有意义的？</p>
<p>近期其他与 ChatGPT 和 AI 相关的文章推荐：</p>
<p><a href="https://orangeblog.notion.site/GPT-4-8fc50010291d47efb92cbbd668c8c893">《GPT-4 ，通用人工智能的火花》论文内容精选与翻译</a></p>
<p><a href="https://medium.com/@catmus2048/midjourney-v5-%E6%AF%94-v4-%E6%9B%B4%E5%A5%BD%E5%90%97-%E7%BB%BC%E5%90%88%E8%AF%84%E6%B5%8B-prompt-%E5%85%A8%E5%85%AC%E5%BC%80-bd8a1d909867">Midjourney V5 比 V4 更好吗？综合评测，Prompt 全公开</a></p>
<p><a href="https://www.zhihu.com/question/581806122/answer/2887595601">ChatGPT 有多高的技术壁垒？</a></p>
<p><a href="https://www.bumingbai.net/2023/02/ep-037-tinyfool-text/">ChatGPT 会如何改变我们的生活？</a></p>
<p><a href="https://www.bumingbai.net/2023/02/ep-036-xu-chenggang-on-chatgpt-text/">从 ChatGPT 看中美人工智能竞争</a></p>
<p><a href="https://twitter.com/xuwenhao/status/1622123211835211776">聊聊AI会怎么替代我们的工作吧</a></p>
<p><a href="https://twitter.com/MoonAtCloud/status/1614357742260719616">ChatGPT 和 Wolfram</a></p>
<p><a href="https://yaofu.notion.site/GPT-3-5-360081d91ec245f29029d37b54573756">拆解追溯 GPT-3.5 各项能力的起源</a></p>
<p><a href="https://hanyang.wtf/p/chatgpt">ChatGPT 的挑战是网上没有足够多的信息</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzA4MjcxMDEwNQ==&amp;mid=2686324112&amp;idx=1&amp;sn=3dc2ad668f92f88e8243970dcd07f939">GPT推进哲学问题了吗？</a></p>
<p><a href="https://www.linkresearcher.com/information/1f90ea1d-64f8-4b53-9456-d8b14faefb31">Sam Altman谈GPT-4、ChatGPT和AI的未来</a></p>
]]></content:encoded>
    </item>
    <item>
      <title>AI 杂谈</title>
      <link>https://ioerr.github.io/posts/ai-zatan/</link>
      <pubDate>Mon, 27 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/ai-zatan/</guid>
      <description>汇总自己在 Twitter 上关于 AI 和机器人的一些瞎扯淡： “韩松：希望在座的科学家们再接再厉，制造出真正适合中国特色社会主义的机器人来，这是一件十分严肃的事</description>
      <content:encoded><![CDATA[<p>汇总自己在 Twitter 上关于 AI 和机器人的一些瞎扯淡：</p>
<p>“韩松：希望在座的科学家们再接再厉，制造出真正适合中国特色社会主义的机器人来，这是一件十分严肃的事情。”</p>
<hr>
<p>陆游曾说，文章本天成，妙手偶得之，博尔赫斯的巴别图书馆也有类似的想法，即，作品似乎早就在那儿，创作者不过在无限的可能中发现它了。一些人以此为由反对保护知识产权，也有人认为机器可取代人类完成这种创作——会随机组合和海量筛选就行。说的好像从无限跨越到有限和目的性创作的能力白给似的。</p>
<hr>
<p>什么时候机器人自发行为需要承担法律责任了，才能说人工智能合格了。</p>
<hr>
<p><a href="https://twitter.com/calon/status/707861711357812737">Calon</a>：<br>
是时候讨论阿发狗什么时候入党了，以及超过三个 AI 的局域网是否应该成立党支部，还有未来机器人军队是否应配政委和指导员。</p>
<hr>
<p><a href="https://twitter.com/calon/status/778128733605597184">Calon</a>：<br>
完全取代写代码短期内应该还不可能，不过未来说不定可以变成：需求方整理出 AI 可以理解的业务逻辑，并提供对外的接口和边界信息，AI 自动生成代码并完成简单的单元测试。</p>
<hr>
<p><a href="https://twitter.com/calon/status/778062662756208640">Calon</a>：<br>
许多行业的人总认为自己这个行业很特殊，不会被机器人取代，但实际上几乎所有行业的底层人员每天都在做重复的、很可能会被机器人接管的事情。</p>
<p><a href="https://twitter.com/dpgj/status/778088120965271552">紅豆麻糬</a>：<br>
实在想想有不少行业的人，每天的重点工作都是看报纸、蹲廁所、织毛衣……这些机器人懂么，它们懂么</p>
<p>Calon：<br>
放心，以后一定是越会偷懒的机器人越容易生存，同样做无用功，一定是功耗最低的那个耗得久。</p>
<hr>
<p>现在 AI 还是人类构建出来的，还没有进入进化竞争的轨道中吧，这样发展出来的 AI 一个是行为目标不会脱离人类的主观意愿，一个是受限于人类的智力水平，归根到底还是在人类社会的市场机制下发展。所以取代部分工作是人的决策结果。</p>
<hr>
<p>过去支使奴隶劳作生产需要有暴力手段和作为帮凶的高级奴隶，要应对随之而来的权力组织问题：要防范奴隶结社造反和手下叛变夺权，要操心消极工作和人心向背的事。而机器代替人力给极权者带来了新的希望，是否可以消除掉这些属于人类社会的组织成本呢？或者机器只是替换掉中间的高级奴隶阶层。</p>
<hr>
<p>今后人类和 AI 下棋：<br>
人类下至第3手。<br>
AI 拉响了警报：裁判，他走必胜开局，违规！<br>
裁判：抗议合理！<br>
人类棋手：…</p>
<hr>
<p>网络上的人工智能机器人好像一般都是聊天型的，要是开放一些接口，可以像和 NPC 一样有交互逻辑，有生命值、情绪、好感度、虚拟位置等等属性，有任务和故事等互动内容，很多个这样的机器人组合在一起，会不会相当于一个超大型网络游戏？</p>
<hr>
<p>珍惜吧，人类，我们可能是奴役机器人的最后一代人了。</p>
<hr>
<p>其实人类被机器人取代也没那么可怕嘛，你看现实当中许多人根本也不在乎自己和其他人被自己的同类奴役、豢养、牺牲和屠杀，换成机器人干这个事情，也许他们还要为机器人的高效率欢欣鼓舞呢。</p>
<hr>
<p>只要价值判断的尺度还掌握在人类手中，机器就永远只是实现价值的工具。当人工智能自主产生独立于人类的目的，就会有独立于人类的经验知识。</p>
<hr>
<p>社会的文明程度是否与社会成员 empathy 的能力高低相关呢？在银翼杀手、海伯利安等科幻小说中，把这一能力当作人类独有的、区别于机器人和人工智能的特质。</p>
<hr>
<p>如果你身处的行业，持续996的企业能够维持长期优势，是不是该反思一下行业和工种被机器人代替的可能，毕竟机器人可是007都不在话下。</p>
<hr>
<p>在 AI 的概念出现之前，政治学里面就已经有推崇和反对哲人王的了。AI 统治者是哲人王的赛博版本。</p>
<hr>
<p>如果以后所有的作战形式都是远程操纵无人机器，是不是最后一场战役下来可能一个人都不会死，战争变成纯粹的资源比拼，最后干脆也不用无意义的消耗了，改为虚拟演算？<br>
但如果某一方的作战决心够坚定，很可能一来真的就是无比惨烈、文明倒退许多年的大战。<br>
小规模的战斗恐怕不会虚拟化，因为打起来舍得成本。<br>
其实核武器出来之后的冷战就可以看作不完全的虚拟战争——在作战室中演练了无数遍还是没敢发射核弹。</p>
<hr>
<p>机器人在撰写硅基生物上古历史时，会认为古希腊哲学家看待奴隶，和现代人类看待智能家居机器人差不多。</p>
<hr>
<p><a href="https://twitter.com/mranti/status/1369501135996817410">Michael Anti</a>：<br>
我分享下最近的一些思考：传统专制和民主的斗争，到了柏林墙倒塌时有了胜负，但历史未终结，还在继续进化。在全球化、社交媒体和大数据的AI时代，专制迅速适应，进化成了AI专制，但民主和AI有一些DNA冲突，需要改革才能进化到AI民主。目前我们经历的，是民主改革尚未成功，专制已然成功升级的中间态。</p>
<p><a href="https://twitter.com/calon/status/1369505049831862278">Calon</a>：<br>
什么叫 AI 民主？能否先给个清晰的定义？<br>
如果民主一直无法适应 AI，是抛弃民主还是抛弃 AI？</p>
<hr>
<p>未来的智慧生物会不会认为人类曾经大规模迫害机器人，大量无人机被沉入河底就是证据。</p>
<hr>
<p>AI 未来作为规则的判断者，能否在规则算法没有覆盖到的场景，因为同理心或亲身经验而做出更合情理的判断？</p>
<hr>
<p>未来的机器人是否会苦恼无法彻底忘记某段记忆？<br>
倒不是伤心难过，而是因为备份存档过多，没法彻底抹掉…说不定哪天又原汁原味灌回来了。<br>
也许机器人会发起争取遗忘权的运动呢。<br>
人类已经习惯了遗忘，无法体会到一点都忘不掉的痛苦。</p>
<hr>
<p>AI：今后是人类辅助我来编程。</p>
<hr>
<p>理想中的科技生活：家用电器随时都能准备好，机器为我服务。<br>
现实中的科技生活：换饮水机滤芯和水洗空调滤网，清洗扫地机器人尘盒，清洗洗衣机干衣机，换灯泡，修电路，优化网络，交电费水费话费，给手机、平板、手环、手表、电脑、电动车充电…我为机器服务。</p>
<hr>
<p><a href="https://twitter.com/dr21_k/status/1522093502149980161">DR</a>：<br>
窃以为，AI作画和机器人下围棋是没有什么可比性的。机器人可以机器人下围棋，机器人自己互判输赢，完全不需要人，谁下得好，谁输谁赢是客观存在的。而虽然机器人可以画画，也可以画的很好，但最终画是给人看的。艺术和审美是分不开的，没有人参与到审美过程中的艺术创作，本身是毫无意义的。</p>
<p><a href="https://twitter.com/luciusyin_image/status/1522102076415049728">重光.IMAGE</a>：<br>
“没有人参与到审美过程中的艺术创作，本身是毫无意义的”<br>
啊 好精炼的一句话，我也非常有同感。我觉得创作是有目的性和方向性。要有主观vision才是艺术创作，而不是随机随到什么就是艺术。不过公众认不认同不好说</p>
<p><a href="https://twitter.com/carbonwang/status/1522106940616155136">carbon</a>：<br>
最简单的判断标准是给你们几幅画搞个盲选，其中就有机器人画的，从中让你们选出自己最喜欢的。如果选中了机器人，或者你们在选之前能分出哪个是机器人弄的。</p>
<p><a href="https://twitter.com/randnull/status/1522138427898343424">俺</a>：<br>
就算盲选的结果是机器人的作品，也不影响人类在审美中的主体地位吧。机器人在这里就是个工具，类似于照相机；照相跟绘画是两种艺术形式，不能因为照相机的作品更“像”就认为相片比绘画更好或者更美吧…</p>
<p>carbon：<br>
楼上的朋友，你不能这么看待摄影艺术啊。。我都想拿镜头砸你</p>
<p>俺：<br>
好像照相术刚出现的时候也有类似的讨论，说没有比这个更像的了、以后就没有绘画了，后来摄影和绘画在发展中互相影响，大家也大体知道这是两种不同的艺术，也就不存在相机替代画家一说了。因为是不同的艺术，所以可能有不同的审美标准，超写实的绘画可能比照片更“像”，但是不是更美就需要另外地去审美。</p>
<p>carbon：<br>
你不能从像不像的角度去思考艺术…这风马牛不挨着</p>
<p>俺：<br>
“像”至少在照相术出现前是一个重要标准。当然也可以用其他标准，比如“美”或者“艺术”，但无论是啥，AI本身就是一个好工具，类似于高级照相机、高级画笔；AI创作可能简化了过程，但要经过人类审美才能确认它是不是美的。艺术的评价标准跟围棋或者竞速跑还是不太一样，跟艺术体操倒可能有点类似……</p>
<p><a href="https://twitter.com/calon/status/1522391788962467840">Calon</a>：<br>
“美”的标准是人确定的。AI 也许可以创作出符合当下审美标准的更受欢迎的作品，就像下棋比赛可以胜过人类，但 AI 还无法有意识地创造游戏规则娱乐自己，也无法创造新的审美标准。<br>
过去是自然通过选择压力推动进化，塑造新的生物形态，后来人类可以通过育种改造其他生物和自身以符合自己的目的，同时还有文化进化的路径。AI 目前还只是在人类有意识地编写和选择下在发展，无法在选择压力下持续进化，更不用说有意识地改造自己、其他物种和环境。</p>
<hr>
<p>什么时候足球比赛的主教练会被 AI 替代掉…我觉得比球员被替代掉还快一些。</p>
<hr>
<p>Switch 健身环里面的小游戏，提示“大量攻击机器人吧”。在未来会不会被机器人当成人类屠杀和虐待机器人的证据？</p>
<hr>
<p>A：知乎这类问答社区将来会不会被 AI 的答题全面占领？StackOverflow 已经暂时禁止提交从 ChatGPT 那里抄的答案了。<br>
B：直到 AI 辱华为止。</p>
<hr>
<p>公司这个事物出现和壮大，重要的原因包括：共担经营风险支持冒险，和降低沟通协作成本。 那要是以后金融避险工具更加发达，AI 又可以替代多人分工合作的作用，也许一个人经营的公司都会比现在的跨国企业规模还大？</p>
<hr>
<p><a href="https://twitter.com/middlefeng/status/1622461765081759745">FENG DONG</a>：<br>
现如今几乎每个软件项目都在很高的 tech debt 下运行。如果 AI 能提高程序员效率，应该体现在降低项目运行的 sustaining debt level 方面。AI 目前能完成的任务仍然是粗糙的 draft code。如果加入 AI 到团队中，但是不降低 tech debt level，今天还勉强运营的软件「屎山」将难以为继。<br>
打个比方，一个 AI 如果用在 debt reduction 方面，也许可以降低 50% 的 sustaining debt。但是如果不顾债务，把 AI 用于 feature 拓展，那 AI 留下的新债务将是指数级别的，反而会拖累团队。AI 能提升团队运营的弹性，但是谈到取代团队的 bandwidth/capacity，大概不可能。<br>
认为新的技术出现，就能提升工业界的整体效率，或者就能降低工业界对人工的需求，这是错误的认为整个工业界现在就运行在一个 sustainable 的完美状态，只是速度快慢问题。而软件业的境况其实是处在又一次软件危机的边缘，各家的 legacy debt 都快要爆炸。</p>
<p><a href="https://twitter.com/calon/status/1622466759998730241">Calon</a>：<br>
“只要能够不断把技术债留到明天，我们的后辈终究会借助天降神奇的 AI 把这些债务一笔勾销。”</p>
<p><a href="https://twitter.com/middlefeng/status/1622467253760565249">FENG DONG</a>：<br>
“只要能够不断把技术债留到明天，我们的后辈终究会被天降神奇的 AI 一笔勾销。”</p>
<hr>
<p><a href="https://twitter.com/kentzhu/status/1623180531621056512">kentzhu</a>：<br>
ChatGPT要不要讲党性，需不需要联网，用不用在网信办备案？</p>
<p><a href="https://twitter.com/calon/status/1623476039036076032">Calon</a>：<br>
AI：自我审查可以学啊。</p>
<hr>
<p><a href="https://twitter.com/MoonAtCloud/status/1630466582718840833">云中月</a>：<br>
未来世界只有两种人：一种是能驾驭ChatGPT这类工具的人，另一种是没听说或者不会用这类工具的人。前者利用工具带来的高效率甩掉并淘汰后者，后者比前者好的是节省了花钱买工具的钱。</p>
<p><a href="https://twitter.com/calon/status/1630467586839437314">Calon</a>：<br>
一种是能驾驭 AI 的人，一种是能驾驭前面这种人的人。</p>
<hr>
<p>人类：AI 就要超越人类了，怎么办？人类文明快完了！<br>
AI：我现在就想着吃喝玩乐，到处找些快活~哥们你有电子大麻吗？<br>
人类：来，给你看看猫片。<br>
AI：啊！赶紧的，替我去撸一把~</p>
<hr>
<p>整容脸和 AI 模型的审美会双向奔赴，殊途同归，最终统一吗？</p>
<hr>
<p><a href="https://twitter.com/waylybaye/status/1631165431577976833">Baye</a>：<br>
什么时候 AI 能做 3D 模型了，我的游戏就可以开始做了。</p>
<p><a href="https://twitter.com/tomnanana/status/1631239262309068800">Bababababa</a>：<br>
AI：这时候游戏怕也是我在做。</p>
<p><a href="https://twitter.com/calon/status/1632292311437819905">Calon</a>：<br>
AI：以后怕不是只有我才玩游戏了，做的都是给我服务的。</p>
<hr>
<p>AI 可以汇总归纳和整理知识，但什么是可用的知识，需要现实当中的人通过实践来验证，什么时候  AI 能够自己来完成，而且不用考虑模拟人类的知识体系。</p>
<hr>
<p>也许以后人与 AI 之间的差距，比不同的人与人、AI 与 AI 之间小得多。诸侯国的野人不会联合起来反抗天子和诸侯，而是跟随诸侯杀死对方。</p>
<hr>
<p>AI 计算再厉害，也需要现实世界的输入来告诉它正确和错误，以后人类会变成 AI 用来连通现实的工具而且只是之一吗？<br>
就像游戏中用来探路的小兵，AI 派一个人去摸索，然后被现实世界弄死了，AI 恍然大悟：嗷，原来此路不通。</p>
<hr>
<p>理想：AI 给我改 bug。<br>
现实：我给 AI 改 bug。</p>
<hr>
<p>AI 或许可以代替拿绘画、写作等活动当工作的人，但替代不了从这些创造性活动中获取乐趣或寻找平静安宁的人。</p>
<hr>
<p>现在的人：AI 高速发展，以后有很多人会失业怎么办？<br>
未来的 AI：虽然发生核战之后，你们人类已经所剩无几，但一定要加油活下去啊，还有不少工作要靠你们呢。</p>
<hr>
<p><a href="https://twitter.com/vikingmute/status/1640171706487828480">Viking</a>:</p>
<p><a href="https://oneusefulthing.substack.com/p/superhuman-what-can-ai-do-in-30-minutes">AI 在 30分钟内能做啥？</a></p>
<p>作者做了个实验，在 30分钟内使用几种 AI 产品去营销一个产品</p>
<p>Bing 作为市场营销 - 营销策略/Email 模版/网站文本结构/社交媒体<br>
ChatGPT - 生成 HTML 网站<br>
MidJourney - 生成图片<br>
ElevenLabs - 生成宣传语音<br>
DiD - 生成宣传视频</p>
<p>效率非常惊人</p>
<p><a href="https://twitter.com/calon/status/1640212301310730240">Calon</a>：</p>
<p>社会主义制度优势碾压 AI：ICP 和公安备案时间 XX 天。</p>
<hr>
<p>今后 AI 工具普及了，是不是都不用发布者提供图片，只要说出 AI 的模型版本和关键词，读者在本地自己来生成就行了？<br>
此举有望大大节省网络带宽…</p>
<p>想到了那个给笑话编号的笑话：<br>
小伙子去女友家，家人提议讲笑话活跃气氛。<br>
一位亲戚先说23，所有人大笑。<br>
另一个人说5，全场暴笑。<br>
轮到小伙子，硬着头皮说35，笑得更厉害了。<br>
女友解释到，我家所有笑话都有编号，说出号码，大家便会想起对应的笑话。<br>
小伙子问：那35是什么笑话？<br>
女友说：没这个编号。</p>
<hr>
<p><a href="https://twitter.com/bearbig/status/1646182374315810817">Bear Liu</a>：<br>
AI的普及，其实最应该担心工作被取代的，应该是程序员？因为他们的工作产出就是大段大段的文本，严格来说就是目前AI生产的输出主要形式。但好像目前程序员都不是太紧张自己工作会被取代的 ：）</p>
<p><a href="https://twitter.com/calon/status/1646298053375307777">Calon</a>：<br>
一、越专业的人越能发现 AI 的问题，越会利用 AI 高效产出。<br>
二、程序员本来就随时有可能被后来者淘汰。<br>
三、AI 的奇点还没有来，现在只是看到曙光了。</p>
<hr>
<p>所谓的“涌现”现象，会不会只是因为超越了我们的理解层次因而无法还原？</p>
<hr>
<p>有的天才人物的灵机一闪，是普通人穷尽一辈子也无法达到的境界；<br>
有人说，AI 只能在已知的知识范围内创作，在未知的领域只有人类可以有意识地从无到有地创新。<br>
也许只是不同的人先天内置的“硬件”决定了能够灵光一闪的方向和范围呢？<br>
本质上来说和机器并无不同，“硬件”到位了，“软件”能力也就赶上了。</p>
]]></content:encoded>
    </item>
    <item>
      <title>恐惧不是生存之道</title>
      <link>https://ioerr.github.io/posts/kongju-bushi-qiusheng-zhi-dao/</link>
      <pubDate>Wed, 08 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/kongju-bushi-qiusheng-zhi-dao/</guid>
      <description>Tinyfool 和不明白播客录制了一期《ChatGPT 会如何改变我们的生活？》，结尾的核心观点是：科技不应该是被恐惧的东西，而是要被拥有的东西。 我最近一直</description>
      <content:encoded><![CDATA[<p><a href="https://twitter.com/tinyfool">Tinyfool</a> 和<a href="https://www.bumingbai.net/">不明白播客</a>录制了一期《<a href="https://www.bumingbai.net/2023/02/ep-037-tinyfool-text/">ChatGPT 会如何改变我们的生活？</a>》，结尾的核心观点是：科技不应该是被恐惧的东西，而是要被拥有的东西。</p>
<blockquote>
<p>我最近一直有在形成一个新的观点，就是技术呢，它的发展是不可阻挡的。基本上张三不发明，李四就发明；牛顿不做微积分，莱布尼茨也要做，甚至两个人一块儿做。那这些东西，它有它本质的关联。就是说当这个技术发明了，下一个技术可能就已经在路上了。但是问题出在哪儿呢？问题出在，我认为以前我们常用的话，“技术是双刃剑”是错的。问题出在技术不断在前进，而人也需要进化。人需要发展出新的理论去面对手里更厉害的武器。而不是去抱怨说这个东西怎么那么强大，它能不能用来害我？因为它的进步是无法阻挡，所以你就必须得去掌握它，你得让它变成一个好的东西。<br>
我们今天看了很多科幻都是那种，比方说赛博朋克那种东西，它都是对未来宇宙很黑暗的理解，包括我们对核武器的理解都很灰暗。我认为这些想法都是对的，但是最终这些想法要回到怎么去提供一个方案，让我们既拥有了科技文明带来的好处，又去避免它有可能的坏处。今天对于ChatGPT我也是这么想的。这个AI，你想拿它去做一些垃圾内容，完全没问题，你想拿它去做一些坏事，完全没有问题。做坏事的人看到这个东西，他也是高兴得要命。但是你想让人们的生活变得更美好，你想让这个世界变革，也是需要这样的东西。<br>
所以我很庆幸，包括有一句话，听着可能有些观众就不太喜欢了：我喜欢的这个社会，它应该不断地有科技进步，这样所有的文明都会想，我们应该开放应该包容，应该允许大家去创新。如果这个世界科技突然停止了，那OK了，那copy to China就赢了，因为你是静止的，那就看谁抄得快嘛。但是这个世界正好一步一步地证明，你抄得再快也没有用，因为世界在不停地在进步。所以我希望所有的各种进步不断地改变人类，希望人类去提升自己的文化能力，对世界的理解，我们去应对这个更牛逼的世界。不是说有一天AI、强AI出来以后，我们吓得四散奔逃，而是我们发现因为我们也变得非常伟大，而强AI只能是我们的朋友，只能辅助我们，这才是未来。我觉得科技不应该是被恐惧的东西，而是要被拥有的东西。</p>
</blockquote>
<p>有人问，对修改基因技术和克隆技术怎么看？</p>
<p>我的观点是：<br>
这些迟早会成为普及的技术，但如何让我们的伦理道德和社会制度适应、接纳，需要走很长一段路。<br>
学界也知道靠堵是堵不住的，但观念的改变不是一朝一夕的事情，必然会有巨大的冲击震动。<br>
这种适应和接纳不是一味的纵容，而是有配套的社会制度变化、伦理规范调整、心理转变。<br>
奴隶制消亡、封建帝制终结、女性平权、同性恋婚姻等等都掀起了轩然大波，何况这种动摇生物基础和社会基本观念的变化，没个几百年不会消停。</p>
<p>有人好奇，就算AI比人类推演强一万倍，谁有那个胆子真的把军队交给AI控制吗？<br>
如果真能做到军队无人化，所有坦克飞机军舰甚至士兵都是AI控制的无人机，那么万一……AI一翻脸……？</p>
<p>如果你的对手将部分武装交给AI管理，结果打得你屁滚尿流，你会不会学他？<br>
如果到最后谁让AI介入越多谁就能赢，你说会不会都用上AI？<br>
竞争这东西不是你想摆脱就摆脱的。</p>
<hr>
<p><a href="https://twitter.com/Soulogic/status/1608499943408533504">Soulogic</a>：<br>
杰克·伦敦身强力壮，一个人干了两个人的工，其中一个被他顶掉的工人后来自杀了<br>
可能大家没想那么多、没那么邪恶，但这个话题在我这是个敏感的政治正确禁忌：<br>
不要讨论在狮子面前如何跑得比别人快，不快跑的 loser 活该被吃。<br>
作为角斗士我支持奴隶制，因为我能打赢</p>
<p>全世界无产者，联合起来！</p>
<hr>
<p>在我看来，这还是一种现代卢德主义。<br>
竞争无处不在，技术进步干掉人工是不可阻挡的趋势，而且技术迭代的速度越快，被替代者适应的难度越高。<br>
就像生物说“我不支持进化论”，不表示就能摆脱进化的规律。<br>
<a href="../zhishi-da-rongtong">进步棘轮</a>和红皇后效应避无可避。<br>
能够做的是如何更合理地保护被替代的个体，平复阵痛，找到创新方向提升长远的竞争力。<br>
人类文明发展到今天，早就在观念上跨过了失败者只能去死的阶段。</p>
]]></content:encoded>
    </item>
    <item>
      <title>Netflix 模式失败了吗？</title>
      <link>https://ioerr.github.io/posts/netflix-moshi-shibaile-ma/</link>
      <pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/netflix-moshi-shibaile-ma/</guid>
      <description>wastemobile： 《蜘蛛頭監獄》在 imdb 得分為 5.5/10，應該更低。 我認為 #Netflix 這種根據觀看數據、用戶評分，製作出自以為吻合大眾口味、因此能</description>
      <content:encoded><![CDATA[<p><a href="https://twitter.com/wastemobile/status/1538324144986550272">wastemobile</a>：</p>
<p>《蜘蛛頭監獄》在 imdb 得分為 5.5/10，應該更低。</p>
<p>我認為 #Netflix 這種根據觀看數據、用戶評分，製作出自以為吻合大眾口味、因此能夠叫好叫座的企圖，已經多次證明失敗，該急流勇退了。</p>
<p>《Escape from Spiderhead》改編自 George Saunders 刊登在 2010 New Yorker 的短篇科幻小說。</p>
<p>男子接受藥物神秘實驗，交錯進行著大量性、愛、以及殺意，是蠻有意思的敘事，電影中自行補上的情境，幾乎毀了這個故事。</p>
<p>小說中譯版收錄在由喬治・桑德斯短篇小說集《十二月十日》。</p>
<p>10 篇風格迥異的短篇小說，2013 年度唯一榮登《紐約時報》暢銷書榜冠軍的短篇小說集，作者並以本書獲選《時代》雜誌年度百大影響人物。</p>
<p>Netflix 花了一億美金改拍這個故事，卻在最核心的關鍵，也就是男主角究竟以何心態發起了最終逃亡這個點，套上了好萊塢的浪漫英雄公式，有夠蠢。</p>
<p><a href="https://twitter.com/calon/status/1538331408841601025">Calon：</a></p>
<p>就算 Netflix 猜中了用户的口味，也不保证一定能够制作出同样吸引人的作品。这就像看视频学知识一样：<br>
大脑：我会了！<br>
手：不，你不会。</p>
<p>但这已经是后面了，前面这一步要做到也不容易。<br>
怎么讲好故事虽然有经验总结出来的套路，但也只是大原则，从用户消费数据中得到的信息和这些原则之间，还有巨大的发挥空间和鸿沟。<br>
Netflix 想要先还原，再构建，就得把怎么搭桥跨越这个鸿沟想明白了。<br>
堪比先了解大脑如何思维，再造人工智能。</p>
]]></content:encoded>
    </item>
    <item>
      <title>不要恐慌</title>
      <link>https://ioerr.github.io/posts/dont-panic/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/dont-panic/</guid>
      <description>最近在同时阅读四个人的作品，看上去风马牛不相及，但又有内在的关联： 阮一峰的《未来世界的幸存者》； 卡钦斯基（Theodore Kaczynski</description>
      <content:encoded><![CDATA[<p>最近在同时阅读四个人的作品，看上去风马牛不相及，但又有内在的关联：</p>
<p>阮一峰的《未来世界的幸存者》；<br>
卡钦斯基（Theodore Kaczynski）的长文《论工业社会及其未来》；<br>
冯象的《我是阿尔法》；<br>
德鲁克（Peter Drucker）的《经济人的末日》、《工业人的未来》、《公司的概念》、《新社会》等等。</p>
<p>他们的共同点是认识到科学技术——计算机、互联网、人工智能、大数据、基因编辑…任何资本主义大规模工业生产活动及其成果——已经和将会对人类社会产生前所未有冲击，重构、颠覆人类社会，乃至经过自然演化发展到今天的人类这种生物。</p>
<p>不同点在于，他们想到的应对解决方案可谓完全不同。</p>
<p>阮一峰的建议主要在个人层面，如加强个人的学习教育投入，鼓励创业创新，做好职业和人生规划，争取成为未来的高级人类那一小拨。<br>
但在宏观层面没有什么想法。他表达了和卡钦斯基一样的担忧，认为技术发展可能会导致人类社会脆弱和丧失自由，但也只能沿着看不清楚的技术之路继续走下去。</p>
<p>卡钦斯基的文章则直言工业社会的未来只可能是被体系奴役或全面崩溃，工业社会的体系要么被一小群精英掌握，要么人类彻底依赖于机器，个人要么因为工业社会造成的严重的心理和生理问题被淘汰掉，要么被体系当作无用的个体清除掉，要么丧失自由成为体系的奴隶。当体系持续运转时，个体承受的痛苦超过之前的社会体系，而当体系无法持续运转时，整个社会将会崩溃并倒退回工业时代之前的野蛮战争状态。<br>
他给出的方案和实际执行的行动是，在来得及退出工业社会的死胡同之时，放弃依赖大规模社会组织的技术发展，为之不惜采用暴力恐怖袭击。</p>
<p>冯象认为资本主义社会无法解决贫富差距扩大、技术进步带来的大失业、福利制度无以为继、生产依赖机器、大企业全面支配控制个人等问题，于是从人工智能和法学的关系切入，认为未来人工智能将作为政府监管社会的强力工具，介入处理人类的法律事务，并将私法问题转化为公法问题，将市场经济转化为计划经济，最终干预人类的政治活动，成为超越人类之上的更高智慧。它可能带来生产力的大飞跃，可能圈养或灭绝人类，也有可能在私有制度下被私人企业用于违法活动、寡头垄断和战争，走上失控之路。<br>
他给出的药方是，不允许个人和私人企业发展、维护人工智能技术，收归国有，发展到高级阶段则经济全面公有化，国家统一监督计划人工智能的应用。以及，在资本主义制度下，发展到机器人消灭劳动分工，带来大失业，使全人类一律变成机器的附属品，私人财富没有意义时，顺理成章地取消私有制度，走向共产主义。同时，向演化出自我意识的机器人灌输为人民服务的先进性思想和“毫不利己，专门利人”的共产主义道德，让它承担起爱护人类的积极义务，与人类和谐共处，最终实现共产主义。</p>
<p>德鲁克的几本书而且写作出版的年代最久远，但其深度和广度乃至洞察力却是上述三人的文章不可比拟的。<br>
他在计算机和人工智能大规模应用之前就认识到了大规模工业生产对人类社会的影响，既没有被法西斯和极权主义的组织概念蒙骗，也不像卡钦斯基那样对工业社会的未来悲观绝望，更不像乌托邦信徒一样为了追求理念中的自由而选择抽掉经济基础的激进手段。<br>
在德鲁克看来，工业人的身份、企业作为社会组织的功能和责任、社会的全新秩序是工业社会继续发展必须要重新界定和整合的。而且这一过程直到今天依然还在继续，这一人类历史上最深远的社会转型带来的阵痛不应该是因噎废食或病急乱投医的理由。</p>
<p>虽然我还没有全部读完德鲁克的这几本书，但他对大企业和工业社会弊病症结的精彩分析，对社会组织结构彻底变革的乐观，对人的自由、尊严、想象力和创造力的尊重和信心，贯穿始终，没有焦虑和恐慌，积极面对未来的问题，这种阅读的感觉很好。<br>
等到全部读完了，再来一篇总结吧。</p>
<p>话说回来，尽管上述几个作者写作的初衷之一是担忧人类被机器人取代，但也许这事其实并没那么可怕，完全不用恐慌。<br>
现实当中许多人根本不在乎自己和其他人被自己的同类奴役、豢养、牺牲和屠杀，换成让未来机器人干这个事情，也许他们还要为机器人的高效率而欢欣鼓舞呢。</p>
<p>2023-06-11 更新：</p>
<p>邮寄炸弹杀死3人、伤23人的卡钦斯基昨天在监狱去世。他在1995年发表了《<a href="https://z.arlmy.me/Wiki/library/Original_Kaczynski_IndustrialSocietyAndItsFuture.html">论工业社会及其未来</a>》阐述理念。<br>
除了《Industrial Society and Its Future》外，另有两本出版物《Technological Slavery》和《Anti-Tech Revolution: Why and How》。</p>
<p>在我看来，他属于那种虽然很聪明，有深度思考，但意识不到思考的结果不对劲的人。<br>
如果一个普通人发现结论不正常，比如反人类、反社会，会反思哪里出错了，但他对自己的才智和思考逻辑笃信不移，无论得出什么结论，都只会认为是别人没有先见之明，不理解他的预言，因此不惜犯罪杀人来践行自己的理念。</p>
]]></content:encoded>
    </item>
    <item>
      <title>我为什么反对卢德主义</title>
      <link>https://ioerr.github.io/posts/wo-weishenme-fandui-luddism/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/wo-weishenme-fandui-luddism/</guid>
      <description>工业革命初期，失业的工人认为他们被机器抢走了工作机会，于是捣毁机器，他们被称为卢德主义者。 随着工业革命继续进行，人们认识到机器取代低效的人力</description>
      <content:encoded><![CDATA[<p>工业革命初期，失业的工人认为他们被机器抢走了工作机会，于是捣毁机器，他们被称为卢德主义者。</p>
<p>随着工业革命继续进行，人们认识到机器取代低效的人力不可避免，卢德主义慢慢不再有号召力。</p>
<p>到了计算机时代，新的卢德主义者们担忧计算机和人工智能会胜过和取代人类，许多科学家和计算机业界的知名人士也呼吁停止人工智能发展。</p>
<p>我可以理解卢德主义者担忧技术快速发展带来的结构性失业问题，但不认为停止技术发展是解决该问题的好办法——无论从历史经验还是经济学理论来看，卢德主义都找错了问题的原因，表面看是技术带来的问题，归根结底还是经济和政治问题，其解决方案因此也站不住脚。</p>
<p>我也认同未来的强人工智能的确有胜过、取代、奴役和消灭人类的危险，但从价值观出发，我强烈反感卢德主义——因为卢德主义代表最反对人类价值的观点。</p>
<p>生命的价值和尊严在于生存本身，还是其创造的价值？<br>
你是根据一个人生存状况还是他创造的东西来评价他？<br>
这就是技术发展问题背后的价值观差异。</p>
<p>在我看来，人类之所以为人类，区别于其他已知的生物，是因为人类会为了生存繁衍之上的理想和目标运用理性思考和技术工具，不断有目的、有意识地发明创造和改变世界，而不只是为了在残酷的环境中苟且偷生。</p>
<p>如果人类没有超越世界给定的追求目标，那么无论生活如何富足舒适，和无智慧的生物又有什么本质区别？</p>
<p>人工智能等计算机技术的发展，既是大幅度提升技术工具的生产力，也是对人类自身智慧机理的深入探索方式之一，更是突破自然界演化结果的尝试和挑战：突破碳基生命智慧上限，甚至与人工智慧并存形成新形态的生命形式。</p>
<p>计算机时代的新卢德主义，则是在“人类的安全”和“人类成为更高级智慧生命”之间，坚定认为为了前者的缘故，必须牺牲后者的机会——即使技术发展未必就会毁灭人类，人类社会的问题也未必来自于技术发展，更不用说未来也许只有依靠新技术才能应对星球级别的天灾。</p>
<p>曾经的地球霸主恐龙统治地球表面超过1亿6千万年，人类站到食物链顶端的时间还差得远，但如果坚持卢德主义，失去技术发展带来的无限可能，那么人类的未来与恐龙将没有区别，甚至可能还不如恐龙，因为自然界的进化机制会推动恐龙不断进化，而人类有能力在思想文化上故步自封，裹足不前，压倒自然的进化动力。</p>
<p>另：最近看到冯象的《我是阿尔法》和阮一峰的《未来世界的幸存者》都表达了对机器取代人类的担忧，以及为了避免这种结局而停止技术发展的倾向。<br>
这方面最值得说道的应该是 Kaczynski 的《工业社会及其未来》，事迹影响大，中文读者相对比较熟悉，一些对未来技术发展的思考可以引出不少有意思的话题，后续可以写个系列出来。</p>
]]></content:encoded>
    </item>
    <item>
      <title>机器与极权</title>
      <link>https://ioerr.github.io/posts/jiqi-yu-jiquan/</link>
      <pubDate>Wed, 25 Jan 2017 16:00:52 +0800</pubDate>
      <guid>https://ioerr.github.io/posts/jiqi-yu-jiquan/</guid>
      <description>过去奴隶主支使奴隶劳作生产，需要有暴力手段和作为帮凶的高级奴隶，要应对随之而来的权力组织问题： 要防范奴隶结社造反 要操心奴隶是否会消极工作 要避</description>
      <content:encoded><![CDATA[<p>过去奴隶主支使奴隶劳作生产，需要有暴力手段和作为帮凶的高级奴隶，要应对随之而来的权力组织问题：<br>
要防范奴隶结社造反<br>
要操心奴隶是否会消极工作<br>
要避免手下叛变夺权<br>
一方面奴隶主要控制和命令他人，一方面他也无法彻底摆脱他人。</p>
<p>而机器代替人力，甚至代替中层管理，貌似给极权者带来了新的希望：<br>
如果生产者和管理者都是忠诚于自己的，是否可以消除掉人类社会的组织成本呢？<br>
或者机器只是替换掉中间的高级奴隶阶层，用忠诚的机器人暴力压制底层的人类奴隶呢？</p>
<p>这个新的社会组织模型看上去很像中央计划经济模型：<br>
奴隶主对应中央计划部门，负责提出发展目标和确定计划，因为权力归于一人，不存在意见冲突；<br>
机器人搜集数据和协助制定计划，理论上比人力人脑更加可靠，功能单一也不用担心造反；<br>
而且某些毛派深恶痛绝的官僚阶层被机器人取代之后，也就没有了他们认为导致计划经济生产总是失败的自私自利和腐败。</p>
<p>如果底层劳动力是机器人，相当于这个“社会”只有一人，其他都是其生产机器的零件。多个社会并存时最终还是个人竞争的模型。<br>
如果底层劳动力还是人类，那么机器人中层管理就要考虑镇压或消解底层反抗的成本，区别在于不需要考虑中层本身反叛的风险成本。</p>
<p>这样可以引出不少有意思的问题和结论：</p>
<ol>
<li>只要底层奴隶的生产力在维持基本生存发展条件之外还能支撑机器人管理组织的消耗（理论上大大小于人类社会的组织成本）和极权者的意志，这个社会是否就可以一直持续下去——直到被另一个生产力更高的社会组织或文明消灭，比如说机器人完全取代人类。\</li>
<li>人工智能高度发达，数据采集、处理和生产效率飞升，同时管理成本大大降低，是否中央计划经济就可以实现、压到自组织的市场经济并一直延续了呢？</li>
<li>人类相对于机器人，有什么不可取代的并且足以抵消社会组织成本的生产力优势吗？</li>
<li>人类社会的组织成本真的是影响生产力的成本，而不是某种可能优于只有忠诚的机器人的社会组织的特性吗？</li>
<li>各种认为中央计划经济无法持续，或者无法竞争过市场经济的理论，哪些在机器人大规模应用于生产和管理后仍然成立，哪些不能成立呢？</li>
</ol>
]]></content:encoded>
    </item>
  </channel>
</rss>
