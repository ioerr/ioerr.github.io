<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>偏见 on 读写错误</title>
    <link>https://ioerr.github.io/tags/%E5%81%8F%E8%A7%81/</link>
    <description>Recent content in 偏见 on 读写错误</description>
    <generator>Hugo -- 0.126.0</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 20 Jan 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://ioerr.github.io/tags/%E5%81%8F%E8%A7%81/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>信息茧房与认知模型</title>
      <link>https://ioerr.github.io/posts/xinxi-jianfang-yu-renzhi-moxing/</link>
      <pubDate>Tue, 20 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/xinxi-jianfang-yu-renzhi-moxing/</guid>
      <description>信息茧房的说法似乎已经成了一种标准解释，但也许是因为这是一种人们更愿意接受的叙事，将制造、加剧偏见的责任完全归咎于控制信息流动的社交媒体平台</description>
      <content:encoded><![CDATA[<p>信息茧房的说法似乎已经成了一种标准解释，但也许是因为这是一种人们更愿意接受的叙事，将制造、加剧偏见的责任完全归咎于控制信息流动的社交媒体平台，而不是主动排斥不相容意见的自己。</p>
<p>需要吸引流量的平台为什么非得以制造和扩大互相认同的群体为目的呢？吸引、挑动对立立场的用户发表越来越极端的观点，更符合平台的利益吧。</p>
<p>所以就算平台要制造信息茧房，也和争议话题养蛊一样，是为极端观点斗兽场服务的工具。<br>
最终还是要打开笼子，让用户接触到伴随对立立场输出的信息。</p>
<p>而且一旦用户意识到存在信息茧房，只要有行动力，当然可以找到大量对立面的信息。<br>
关键在于如何处理这些信息，是通过区别对待来不断强化自己的观点，还是带着批判思考来找到值得吸纳的对立面信息。</p>
<p>与信息供给同样重要的是认知模型。<br>
基于糟糕的认知模型可以忽略一切常识，精准命中信息鱼饵，而拥有基础坚实的认知模型，在海量的垃圾中也可以发现可信的信息。</p>
<p>其他人面对同样的信息得出相反结论时，人们常会惊讶或愤怒。这是因为他们总认为所有人的认知模型应该高度一致。<br>
不承认这种差异的结果就是：<br>
不会运用的人是蠢；<br>
会运用却不好好用的人是坏；<br>
以及，错的都是其他人，我的认知模型不可能出错也不需要调整。</p>
<p>而这正是信息茧房得以成立的基础之一，先有了认知的傲慢，然后才有对信息茧房叙事的认同，以及对自身责任的忽视和逃避。</p>
<p>单方面的信息灌输在形成初始偏见时当然影响重大，所以信息茧房依然值得批判。<br>
但一个开放的、能不断自我驱动调整的认知模型，是抵消这种负面影响的内在动力。</p>
<p>而在评估外界信息时，评估信息者主体的认知模型比信息本身更重要。<br>
如果对方的认知模型是一个封闭、没有自我批判反省能力的模式，或者是缺乏有效鉴别方法的模式，那么其可信度当然要大打折扣。</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
