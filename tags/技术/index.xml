<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>技术 on 读写错误</title>
    <link>https://ioerr.github.io/tags/%E6%8A%80%E6%9C%AF/</link>
    <description>Recent content in 技术 on 读写错误</description>
    <generator>Hugo -- 0.126.0</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 26 Feb 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://ioerr.github.io/tags/%E6%8A%80%E6%9C%AF/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>政治和技术对崩溃的影响</title>
      <link>https://ioerr.github.io/posts/zhengzhi-he-jishu-dui-bengkui-de-yingxiang/</link>
      <pubDate>Mon, 26 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/zhengzhi-he-jishu-dui-bengkui-de-yingxiang/</guid>
      <description>土摩托： 我觉得仅凭政治制度的腐败是无法导致崩溃的…只有全球气候变化这样级别的环境灾难才能导致崩溃。换句话说，政治制度只是信息，只有能源（以及</description>
      <content:encoded><![CDATA[<p>土摩托：<br>
我觉得仅凭政治制度的腐败是无法导致崩溃的…只有全球气候变化这样级别的环境灾难才能导致崩溃。换句话说，政治制度只是信息，只有能源（以及材料）的断档才能导致人类社会的彻底崩溃。</p>
<p><a href="https://twitter.com/calon/status/1761904489127399635">Calon</a>：<br>
崩溃没那么容易。<br>
政治制度影响到的是在危机面前先消耗掉哪一部分人，对这些人而言，日常就是被消耗的耗材，崩溃不崩溃没什么区别。<br>
政治文化则影响到这些人对被消耗的命运感到不公还是光荣。<br>
技术成果如何分配到每个人，也是政治的概念。<br>
技术进步可以让人吃饱饭，也可能是被破坏抵制的纺织机、电线杆、铁路、核电站，以及让外卖骑手疲于奔命的系统——人们更多的是在反抗技术背后的分配权力。</p>
<p>技术进步确实可以让生产力突飞猛进，解决政治制度解决不了的问题。<br>
但是，政治制度也可以让技术进步的成果向权力分配者无限倾斜，让被消耗者心甘情愿当耗材，让技术进步意图解决的问题无限延续和扩大，直到在沙漠里连沙子都会短缺。</p>
]]></content:encoded>
    </item>
    <item>
      <title>尊重认知差异，隔离试验风险</title>
      <link>https://ioerr.github.io/posts/zunzhong-renzhi-chayi-geli-shiyan-fengxian/</link>
      <pubDate>Thu, 09 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/zunzhong-renzhi-chayi-geli-shiyan-fengxian/</guid>
      <description>在知乎上 ChatGPT 有多高的技术壁垒？国内外除了 OpenAI 还有谁可以做到类似程度？的回答中，回答者华严的核心观点是： 人的行为对市场的影响很难预测。 技术演进基本</description>
      <content:encoded><![CDATA[<p>在知乎上 <a href="https://www.zhihu.com/question/581806122/">ChatGPT 有多高的技术壁垒？国内外除了 OpenAI 还有谁可以做到类似程度？</a>的<a href="https://www.zhihu.com/question/581806122/answer/2887595601">回答</a>中，回答者<a href="https://www.zhihu.com/people/hua-yan">华严</a>的核心观点是：</p>
<blockquote>
<p>人的行为对市场的影响很难预测。<br>
技术演进基本都是每一小步都需要获得正反馈，在正反馈和负反馈各自的激励下走出技术发展的实际路径，而对市场环境的粗暴干预则会改变激励机制，从而影响技术路径。<br>
不必要的干预在前期所带来的某项成本的微小提升，可能会直接影响到技术路径的选择和演化，这个效应不断被放大，最后造成天壤之别的结果。<br>
你对市场的干预和限制越多，市场给你的惊喜就越少，经济学规律是公平的。</p>
</blockquote>
<p>电子游戏的禁令、版号收紧、言论控制、监管审批等等都是干预和限制的例子。</p>
<p>有的人不理解，认为这个回答是事后诸葛亮，是被 ChatGPT 吓到后的愤怒发泄、情绪输出，是为无能推卸责任找借口，最终将问题归咎于意识形态是掺杂<a href="../jiadai-sihuo-he-fuduji">私货</a>。</p>
<p>干预每一步造成的微小影响，本来就不是每个人都能够认同的。<br>
你说有因果关系，他说没有因果关系，最终谁也说服不了谁，因为两类人的认知就不一样。<br>
社会发展又不是实验室里的试验，能够严格控制变量，你动了 A，B 就一定会发生的，最终还是看每个人的认知能力。</p>
<p>而认知的差异大多来自于对市场与技术演进机制的认识不同，这个认识的差异决定了，拿任何现实中的例子和数据出来说，都只会固化、加强自己的观点。<br>
最后看上去就成了信念甚至信仰的争论，互指对方是傻逼，这么简单的因果关系都看不出。</p>
<p>这也就是为什么要鼓励多元观念并存和风险隔离。<br>
最理想的是（可惜现实不可能这么理想）每个人都有自己的<a href="https://www.youtube.com/watch?v=Ka8_-ciDJfA">试验田</a>，可以自愿合作、合伙、合并，对自己观念落到现实的结果负责，与人基本无害。<br>
你说你有理，结果最差大不了也就是在试验田范围内自我毁灭了。</p>
<p>最怕就是那种，我觉得我有理，我通天晓地掌握了历史规律，未来尽在掌握，你们这些废物做的都是奇技淫巧无用之功，所有人必须集中力量听我统一指挥。<br>
结果未来的发展不是那么称心如意，最后出岔子偏离设想的道路了，又变成甩锅第一名。<br>
出发点是好的，大方向没有问题，就是执行有一点偏差和意外，只要其他人去死一死，剩下的人继续保持信念、万众一心，最终必将胜利。</p>
]]></content:encoded>
    </item>
    <item>
      <title>恐惧不是生存之道</title>
      <link>https://ioerr.github.io/posts/kongju-bushi-qiusheng-zhi-dao/</link>
      <pubDate>Wed, 08 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/kongju-bushi-qiusheng-zhi-dao/</guid>
      <description>Tinyfool 和不明白播客录制了一期《ChatGPT 会如何改变我们的生活？》，结尾的核心观点是：科技不应该是被恐惧的东西，而是要被拥有的东西。 我最近一直</description>
      <content:encoded><![CDATA[<p><a href="https://twitter.com/tinyfool">Tinyfool</a> 和<a href="https://www.bumingbai.net/">不明白播客</a>录制了一期《<a href="https://www.bumingbai.net/2023/02/ep-037-tinyfool-text/">ChatGPT 会如何改变我们的生活？</a>》，结尾的核心观点是：科技不应该是被恐惧的东西，而是要被拥有的东西。</p>
<blockquote>
<p>我最近一直有在形成一个新的观点，就是技术呢，它的发展是不可阻挡的。基本上张三不发明，李四就发明；牛顿不做微积分，莱布尼茨也要做，甚至两个人一块儿做。那这些东西，它有它本质的关联。就是说当这个技术发明了，下一个技术可能就已经在路上了。但是问题出在哪儿呢？问题出在，我认为以前我们常用的话，“技术是双刃剑”是错的。问题出在技术不断在前进，而人也需要进化。人需要发展出新的理论去面对手里更厉害的武器。而不是去抱怨说这个东西怎么那么强大，它能不能用来害我？因为它的进步是无法阻挡，所以你就必须得去掌握它，你得让它变成一个好的东西。<br>
我们今天看了很多科幻都是那种，比方说赛博朋克那种东西，它都是对未来宇宙很黑暗的理解，包括我们对核武器的理解都很灰暗。我认为这些想法都是对的，但是最终这些想法要回到怎么去提供一个方案，让我们既拥有了科技文明带来的好处，又去避免它有可能的坏处。今天对于ChatGPT我也是这么想的。这个AI，你想拿它去做一些垃圾内容，完全没问题，你想拿它去做一些坏事，完全没有问题。做坏事的人看到这个东西，他也是高兴得要命。但是你想让人们的生活变得更美好，你想让这个世界变革，也是需要这样的东西。<br>
所以我很庆幸，包括有一句话，听着可能有些观众就不太喜欢了：我喜欢的这个社会，它应该不断地有科技进步，这样所有的文明都会想，我们应该开放应该包容，应该允许大家去创新。如果这个世界科技突然停止了，那OK了，那copy to China就赢了，因为你是静止的，那就看谁抄得快嘛。但是这个世界正好一步一步地证明，你抄得再快也没有用，因为世界在不停地在进步。所以我希望所有的各种进步不断地改变人类，希望人类去提升自己的文化能力，对世界的理解，我们去应对这个更牛逼的世界。不是说有一天AI、强AI出来以后，我们吓得四散奔逃，而是我们发现因为我们也变得非常伟大，而强AI只能是我们的朋友，只能辅助我们，这才是未来。我觉得科技不应该是被恐惧的东西，而是要被拥有的东西。</p>
</blockquote>
<p>有人问，对修改基因技术和克隆技术怎么看？</p>
<p>我的观点是：<br>
这些迟早会成为普及的技术，但如何让我们的伦理道德和社会制度适应、接纳，需要走很长一段路。<br>
学界也知道靠堵是堵不住的，但观念的改变不是一朝一夕的事情，必然会有巨大的冲击震动。<br>
这种适应和接纳不是一味的纵容，而是有配套的社会制度变化、伦理规范调整、心理转变。<br>
奴隶制消亡、封建帝制终结、女性平权、同性恋婚姻等等都掀起了轩然大波，何况这种动摇生物基础和社会基本观念的变化，没个几百年不会消停。</p>
<p>有人好奇，就算AI比人类推演强一万倍，谁有那个胆子真的把军队交给AI控制吗？<br>
如果真能做到军队无人化，所有坦克飞机军舰甚至士兵都是AI控制的无人机，那么万一……AI一翻脸……？</p>
<p>如果你的对手将部分武装交给AI管理，结果打得你屁滚尿流，你会不会学他？<br>
如果到最后谁让AI介入越多谁就能赢，你说会不会都用上AI？<br>
竞争这东西不是你想摆脱就摆脱的。</p>
<hr>
<p><a href="https://twitter.com/Soulogic/status/1608499943408533504">Soulogic</a>：<br>
杰克·伦敦身强力壮，一个人干了两个人的工，其中一个被他顶掉的工人后来自杀了<br>
可能大家没想那么多、没那么邪恶，但这个话题在我这是个敏感的政治正确禁忌：<br>
不要讨论在狮子面前如何跑得比别人快，不快跑的 loser 活该被吃。<br>
作为角斗士我支持奴隶制，因为我能打赢</p>
<p>全世界无产者，联合起来！</p>
<hr>
<p>在我看来，这还是一种现代卢德主义。<br>
竞争无处不在，技术进步干掉人工是不可阻挡的趋势，而且技术迭代的速度越快，被替代者适应的难度越高。<br>
就像生物说“我不支持进化论”，不表示就能摆脱进化的规律。<br>
<a href="../zhishi-da-rongtong">进步棘轮</a>和红皇后效应避无可避。<br>
能够做的是如何更合理地保护被替代的个体，平复阵痛，找到创新方向提升长远的竞争力。<br>
人类文明发展到今天，早就在观念上跨过了失败者只能去死的阶段。</p>
]]></content:encoded>
    </item>
    <item>
      <title>不要恐慌</title>
      <link>https://ioerr.github.io/posts/dont-panic/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/dont-panic/</guid>
      <description>最近在同时阅读四个人的作品，看上去风马牛不相及，但又有内在的关联： 阮一峰的《未来世界的幸存者》； 卡钦斯基（Theodore Kaczynski</description>
      <content:encoded><![CDATA[<p>最近在同时阅读四个人的作品，看上去风马牛不相及，但又有内在的关联：</p>
<p>阮一峰的《未来世界的幸存者》；<br>
卡钦斯基（Theodore Kaczynski）的长文《论工业社会及其未来》；<br>
冯象的《我是阿尔法》；<br>
德鲁克（Peter Drucker）的《经济人的末日》、《工业人的未来》、《公司的概念》、《新社会》等等。</p>
<p>他们的共同点是认识到科学技术——计算机、互联网、人工智能、大数据、基因编辑…任何资本主义大规模工业生产活动及其成果——已经和将会对人类社会产生前所未有冲击，重构、颠覆人类社会，乃至经过自然演化发展到今天的人类这种生物。</p>
<p>不同点在于，他们想到的应对解决方案可谓完全不同。</p>
<p>阮一峰的建议主要在个人层面，如加强个人的学习教育投入，鼓励创业创新，做好职业和人生规划，争取成为未来的高级人类那一小拨。<br>
但在宏观层面没有什么想法。他表达了和卡钦斯基一样的担忧，认为技术发展可能会导致人类社会脆弱和丧失自由，但也只能沿着看不清楚的技术之路继续走下去。</p>
<p>卡钦斯基的文章则直言工业社会的未来只可能是被体系奴役或全面崩溃，工业社会的体系要么被一小群精英掌握，要么人类彻底依赖于机器，个人要么因为工业社会造成的严重的心理和生理问题被淘汰掉，要么被体系当作无用的个体清除掉，要么丧失自由成为体系的奴隶。当体系持续运转时，个体承受的痛苦超过之前的社会体系，而当体系无法持续运转时，整个社会将会崩溃并倒退回工业时代之前的野蛮战争状态。<br>
他给出的方案和实际执行的行动是，在来得及退出工业社会的死胡同之时，放弃依赖大规模社会组织的技术发展，为之不惜采用暴力恐怖袭击。</p>
<p>冯象认为资本主义社会无法解决贫富差距扩大、技术进步带来的大失业、福利制度无以为继、生产依赖机器、大企业全面支配控制个人等问题，于是从人工智能和法学的关系切入，认为未来人工智能将作为政府监管社会的强力工具，介入处理人类的法律事务，并将私法问题转化为公法问题，将市场经济转化为计划经济，最终干预人类的政治活动，成为超越人类之上的更高智慧。它可能带来生产力的大飞跃，可能圈养或灭绝人类，也有可能在私有制度下被私人企业用于违法活动、寡头垄断和战争，走上失控之路。<br>
他给出的药方是，不允许个人和私人企业发展、维护人工智能技术，收归国有，发展到高级阶段则经济全面公有化，国家统一监督计划人工智能的应用。以及，在资本主义制度下，发展到机器人消灭劳动分工，带来大失业，使全人类一律变成机器的附属品，私人财富没有意义时，顺理成章地取消私有制度，走向共产主义。同时，向演化出自我意识的机器人灌输为人民服务的先进性思想和“毫不利己，专门利人”的共产主义道德，让它承担起爱护人类的积极义务，与人类和谐共处，最终实现共产主义。</p>
<p>德鲁克的几本书而且写作出版的年代最久远，但其深度和广度乃至洞察力却是上述三人的文章不可比拟的。<br>
他在计算机和人工智能大规模应用之前就认识到了大规模工业生产对人类社会的影响，既没有被法西斯和极权主义的组织概念蒙骗，也不像卡钦斯基那样对工业社会的未来悲观绝望，更不像乌托邦信徒一样为了追求理念中的自由而选择抽掉经济基础的激进手段。<br>
在德鲁克看来，工业人的身份、企业作为社会组织的功能和责任、社会的全新秩序是工业社会继续发展必须要重新界定和整合的。而且这一过程直到今天依然还在继续，这一人类历史上最深远的社会转型带来的阵痛不应该是因噎废食或病急乱投医的理由。</p>
<p>虽然我还没有全部读完德鲁克的这几本书，但他对大企业和工业社会弊病症结的精彩分析，对社会组织结构彻底变革的乐观，对人的自由、尊严、想象力和创造力的尊重和信心，贯穿始终，没有焦虑和恐慌，积极面对未来的问题，这种阅读的感觉很好。<br>
等到全部读完了，再来一篇总结吧。</p>
<p>话说回来，尽管上述几个作者写作的初衷之一是担忧人类被机器人取代，但也许这事其实并没那么可怕，完全不用恐慌。<br>
现实当中许多人根本不在乎自己和其他人被自己的同类奴役、豢养、牺牲和屠杀，换成让未来机器人干这个事情，也许他们还要为机器人的高效率而欢欣鼓舞呢。</p>
<p>2023-06-11 更新：</p>
<p>邮寄炸弹杀死3人、伤23人的卡钦斯基昨天在监狱去世。他在1995年发表了《<a href="https://z.arlmy.me/Wiki/library/Original_Kaczynski_IndustrialSocietyAndItsFuture.html">论工业社会及其未来</a>》阐述理念。<br>
除了《Industrial Society and Its Future》外，另有两本出版物《Technological Slavery》和《Anti-Tech Revolution: Why and How》。</p>
<p>在我看来，他属于那种虽然很聪明，有深度思考，但意识不到思考的结果不对劲的人。<br>
如果一个普通人发现结论不正常，比如反人类、反社会，会反思哪里出错了，但他对自己的才智和思考逻辑笃信不移，无论得出什么结论，都只会认为是别人没有先见之明，不理解他的预言，因此不惜犯罪杀人来践行自己的理念。</p>
]]></content:encoded>
    </item>
    <item>
      <title>Gattaca</title>
      <link>https://ioerr.github.io/posts/gattaca/</link>
      <pubDate>Tue, 27 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/gattaca/</guid>
      <description>Ethan Hawke、Uma Thurman 和 Jude Law 于1997年出演的电影《Gattaca》在我心目中可以排在科幻电影前三位。 主流电影中讨论基因改造话题的不算多，《</description>
      <content:encoded><![CDATA[<p>Ethan Hawke、Uma Thurman 和 Jude Law 于1997年出演的电影《Gattaca》在我心目中可以排在科幻电影前三位。<br>
主流电影中讨论基因改造话题的不算多，《Gattaca》想象了基因改造技术对人类社会和个体的影响，以及基因和命运不如他人完美的个人如何挑战被基因决定的未来和追求毕生理想。<br>
剧情、演技、节奏、画面风格（当前时间线的日间都是昏黄的特殊色调）、音乐（强烈推荐）都相当出色。</p>
<p>可惜限于篇幅，电影只是展示了两位主人公的命运起伏，而且让其中一位开了挂，另外只用较小的篇幅提到了“劣等基因”阶层的生存状况。<br>
如果能更加深入地探讨基因改造造成社会阶层隔离的后续如何发展，就可以在我心目中排到第一了。<br>
我就想看看，如果按基因编辑人种就是在各方面超过自然生育进化的人种来推想，最终社会会发展成为什么样子。<br>
不要有逆天的主角靠意志突破先天的优势壁垒，不要像某些超能力英雄一样跑出来说能力越大责任越大——蜘蛛侠也好，X Man 也好，真出现了这样能力远远超过常人的存在，我反正不会寄希望于毫无约束的至善人性，会始终主动冒着生命危险保护弱者。</p>
<p>不过如果继续深入挖掘这个题材，也许需要扩充为电视剧集的长度才行，这几年连《西部世界》都翻拍和扩充成为电视剧集，《Gattaca》应该也可以享受这个待遇吧。</p>
<p>为什么忽然想到《Gattaca》呢，因为基因技术改造人类带来的影响在我们这一辈就快要不是科幻话题了。<br>
<a href="http://www.zhishifenzi.com/news/multiple/4667.html">世界首例基因编辑婴儿露露和娜娜在中国诞生</a>，全球首例基因编辑人体试验已经成为事实，在学界和社会掀起了轩然大波。</p>
<p>目前学界争论的焦点是一系列现实问题：试验是否成功，是否遵循了伦理原则，是否让试验对象承受了不必要的风险，试验对象的个人权利如何保障？<br>
试验项目负责人贺建奎的激进冒险，将反对基因编辑技术和希望技术稳步前进的两群人，以及持这两种态度的公众，都一下子推到了对立面。<br>
短期内，类似的试验会更加严格限制，甚至因为公众的恐惧而大大降低民众对科学团体的信任，影响正常的技术发展和试验开展。</p>
<p>然而，应该看到，基因编辑的技术突破和应用是不可阻挡的趋势，不可能永远限制住——事实已经证明，现在就很难限制住了。<br>
基因工程不像基础物理试验，相对较低的预算也可以拉出小团队悄悄地甩开伦理审查弄地下试验，又有足够的利益驱动，所以我很不看好靠伦理审查能够挡住这类技术应用。<br>
短期内只能寄希望于技术不够成熟，效果还不理想，希望应用基因编辑的买家持续观望。<br>
长期来看，虽然现在人类对基因片段和基因组生效的效果和机制还不甚了了，基因编辑手段也不够成熟，但这只是时间问题。只要技术有理论可能和应用的需求前景，就一定会被发展出来投入使用并不断优化，到那个时候，有需求有供给能力，就很难禁绝。<br>
我们能做的，除了努力使基因编辑技术的发展尽量降低风险和争议，在可控中前进，也要开始从心理和制度上慢慢适应可能会出现新型人类的社会了。</p>
<p>许多人害怕应用基因编辑技术定制新型人类，其实不是关心伦理问题——医学伦理和人类定义的哲学问题他们既不了解也不关心，主要是担心财富和资源的多寡从出生开始就可以拉开不同阶层的身体硬件条件上的鸿沟，这进一步加剧了当前社会对阶层彻底固化的焦虑。</p>
<p>有的人认为，基因编辑技术会像历史上所有的民用级技术一样，在成熟和推广开来后，成本不断降低，市场不断扩大，最终总会从富人的玩具变成平民的日用品，不会成为富人的专利。<br>
但毕竟谁也不能打包票说未来就会如此发展，特别是基因编辑改变的是底层的硬件参数，其影响和过去的技术进步不可同日而语。</p>
<p>最可能的糟糕结果，就是有资格应用基因编辑技术的少数人，利用短期内形成的智力和体力优势壁垒，形成对其余大多数人的彻底压制，最终演变成永恒的奴隶主和奴隶阶层，或者干脆变成高阶新人类与低阶旧人类的对立。<br>
这在科幻作品和社会制度批判方面是非常常见的观点，但我们通常看到的都是如何避免这种情况出现，而不是一旦真的形成这种人种级别的压制优势，被压制的旧人类、低级阶层一方是否还有翻身、争取对等地位和维持生存的可能？</p>
<p>掌握了基因技术之后，人类最舍不得放弃的恐怕就是寿命了。<br>
其他方面都可以依靠基因编辑不断优化，但断不会有人故意负“优化”自身的寿命，否则就把自己变成了银翼杀手中的人造人。<br>
高阶新人类唯一的弱点也许就在于此。理解了达尔文演化论的人明白，长寿是个体所追求的，但对物种而言说不上绝对的好坏。</p>
<p>也许今后无法用上基因编辑技术的低阶旧人类在灭绝之前，会为环境所迫发展成为大量繁殖、快速死亡和演化的新物种。<br>
（当然，虽然不能应用基因编辑技术，却必须要能通过其他技术快速传承知识，维持智力上的差距不被拉得太大。）<br>
就像奇幻小说中，人类相对于精灵族一样，短寿、低能、野蛮，但繁殖和适应能力优越，成为高级病毒。</p>
<p>一旦高阶人类这种长寿物种自身迭代的速度赶不上低阶人类不惜短寿快速迭代的速度，也许后者才有些许胜机或生机。</p>
<p>要么就是，因为拼命抗拒死亡的规律，超出合理程度的长寿，带来资源短缺和争抢，无法在社会制度层面解决资源重新分配的问题，从而导致内战和崩溃。但低阶旧人类能否从中获利还很难说。</p>
<p>或者，是基因改造方向大量趋同，导致基因库多样性严重下降，被未能预料到的自然界危机一波消灭。<br>
但我相信以新人类经过提升的智力，还不至于犯这么低级的错误。</p>
<p>当然，也有可能高阶新人类迅速灭绝或放逐了低阶旧人类，杜绝了任何翻盘的可能，就像智人消灭了所有的近亲物种，成为这一支上的独苗。<br>
作为旧人类的一员，最好还是祈祷以上多种可能晚一点成真吧。</p>
]]></content:encoded>
    </item>
    <item>
      <title>我为什么反对卢德主义</title>
      <link>https://ioerr.github.io/posts/wo-weishenme-fandui-luddism/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/wo-weishenme-fandui-luddism/</guid>
      <description>工业革命初期，失业的工人认为他们被机器抢走了工作机会，于是捣毁机器，他们被称为卢德主义者。 随着工业革命继续进行，人们认识到机器取代低效的人力</description>
      <content:encoded><![CDATA[<p>工业革命初期，失业的工人认为他们被机器抢走了工作机会，于是捣毁机器，他们被称为卢德主义者。</p>
<p>随着工业革命继续进行，人们认识到机器取代低效的人力不可避免，卢德主义慢慢不再有号召力。</p>
<p>到了计算机时代，新的卢德主义者们担忧计算机和人工智能会胜过和取代人类，许多科学家和计算机业界的知名人士也呼吁停止人工智能发展。</p>
<p>我可以理解卢德主义者担忧技术快速发展带来的结构性失业问题，但不认为停止技术发展是解决该问题的好办法——无论从历史经验还是经济学理论来看，卢德主义都找错了问题的原因，表面看是技术带来的问题，归根结底还是经济和政治问题，其解决方案因此也站不住脚。</p>
<p>我也认同未来的强人工智能的确有胜过、取代、奴役和消灭人类的危险，但从价值观出发，我强烈反感卢德主义——因为卢德主义代表最反对人类价值的观点。</p>
<p>生命的价值和尊严在于生存本身，还是其创造的价值？<br>
你是根据一个人生存状况还是他创造的东西来评价他？<br>
这就是技术发展问题背后的价值观差异。</p>
<p>在我看来，人类之所以为人类，区别于其他已知的生物，是因为人类会为了生存繁衍之上的理想和目标运用理性思考和技术工具，不断有目的、有意识地发明创造和改变世界，而不只是为了在残酷的环境中苟且偷生。</p>
<p>如果人类没有超越世界给定的追求目标，那么无论生活如何富足舒适，和无智慧的生物又有什么本质区别？</p>
<p>人工智能等计算机技术的发展，既是大幅度提升技术工具的生产力，也是对人类自身智慧机理的深入探索方式之一，更是突破自然界演化结果的尝试和挑战：突破碳基生命智慧上限，甚至与人工智慧并存形成新形态的生命形式。</p>
<p>计算机时代的新卢德主义，则是在“人类的安全”和“人类成为更高级智慧生命”之间，坚定认为为了前者的缘故，必须牺牲后者的机会——即使技术发展未必就会毁灭人类，人类社会的问题也未必来自于技术发展，更不用说未来也许只有依靠新技术才能应对星球级别的天灾。</p>
<p>曾经的地球霸主恐龙统治地球表面超过1亿6千万年，人类站到食物链顶端的时间还差得远，但如果坚持卢德主义，失去技术发展带来的无限可能，那么人类的未来与恐龙将没有区别，甚至可能还不如恐龙，因为自然界的进化机制会推动恐龙不断进化，而人类有能力在思想文化上故步自封，裹足不前，压倒自然的进化动力。</p>
<p>另：最近看到冯象的《我是阿尔法》和阮一峰的《未来世界的幸存者》都表达了对机器取代人类的担忧，以及为了避免这种结局而停止技术发展的倾向。<br>
这方面最值得说道的应该是 Kaczynski 的《工业社会及其未来》，事迹影响大，中文读者相对比较熟悉，一些对未来技术发展的思考可以引出不少有意思的话题，后续可以写个系列出来。</p>
]]></content:encoded>
    </item>
    <item>
      <title>现代杞人忧天</title>
      <link>https://ioerr.github.io/posts/xiandai-qirenyoutian/</link>
      <pubDate>Wed, 29 Mar 2017 12:11:30 +0800</pubDate>
      <guid>https://ioerr.github.io/posts/xiandai-qirenyoutian/</guid>
      <description>阮一峰最近在《技术的边界》中提到一个不算新鲜的观点：技术高速发展所蕴含的巨大能量，最终将把人类社会带到难以预测的脆弱状态。 其逻辑要点是： 系统</description>
      <content:encoded><![CDATA[<p>阮一峰最近在<a href="www.ruanyifeng.com/blog/2017/03/boundary.html">《技术的边界》</a>中提到一个不算新鲜的观点：技术高速发展所蕴含的巨大能量，最终将把人类社会带到难以预测的脆弱状态。</p>
<p>其逻辑要点是：</p>
<ol>
<li>
<p>系统越来越复杂，分工越来越细，大多数人已经不能够理解技术了，一个人也不可能从头到尾掌握整个系统。</p>
</li>
<li>
<p>因为无法理解技术，人类不知道今后技术会突破到什么程度。</p>
</li>
<li>
<p>只要技术有能力做到的事情，最终都会做到。人类没有办法遏制它的发展。</p>
</li>
<li>
<p>无法理解和无法控制发展，因此人类无法控制新技术的后果，可能实现能摧毁文明的技术。</p>
</li>
<li>
<p>结论：依赖技术的高科技、高度自动化的社会非常脆弱。</p>
</li>
</ol>
<p>我觉得这完全是现代版的杞人忧天：</p>
<p>细致分工导致隔行如隔山、一个人无法掌握整个系统，不是大问题。<br>
只要人类的沟通、交流、利益驱动、组织能力还在，分别掌握了技术细节的人可以随时组织起来，重建技术文明。<br>
而且历史证明，行业分工合作的社会，其竞争力远超没有分工的社会，从头再来仍然还会是这个结果，从分工导致的现象开始担忧没有道理。</p>
<p>人类无法预测技术的未来发展也不是大问题。<br>
事实上人类从来就没有搞清楚技术的未来在什么方向，只是技术进步的速度加快，让现代人普遍能体会到这种对未来的无知。<br>
我看到有网友评论得好：这种担忧只是人类对未知的原始本能的恐惧。</p>
<p>技术上能够实现的事情最终都会实现也不是大问题。<br>
这种表述方式有点像 Kevin Kelly 的《What Technology Wants》中将技术视为某种生命存在方式，或者盖亚假说中将整个地球生态视为有意识有目的的生命。<br>
仿佛冥冥之中人类会不由自主地为技术这种生命形式的目的服务。<br>
但实际上决定某项技术能否实现的，归根到底是人类的需求。</p>
<p>我们看到的许多实现难度很高或者为主流社会不容的技术突破，都是因为有人类需求源源不断地驱动。<br>
这需求不止是要用真金白银兑现的市场需求，也包括人类天生好奇心所催生的不求回报的需求。<br>
而同时，还有海量的本可能实现，但因为缺少需求驱动而胎死腹中、脑中的潜在的技术突破点，根本不需要妄图阻止技术进步的卢德主义者出手，就默默无闻地消失在历史长河中了，而我们只能看到那些突破重重险阻实现了的。<br>
一旦落到人类自身需求的层面上来，对技术发展的担忧就转变为对人类社会组织存续能力的担忧。</p>
<p>新技术不可控的问题那得看是对谁而言。<br>
如果你是希望全局掌控社会发展动态的控制狂，那么这确实是大问题。<br>
但如果你明白社会竞争发展的常态本来就是一种“基本可控的不可控”状态，那么这也不是什么大问题。</p>
<p>要担心的是能够一下子毁灭所有人类的技术被某个漠视现世价值的疯子掌握，或者技术发展导致人类的演变出现严重撕裂社会进而引起世界战争的情况。<br>
但这也不是技术层面的问题，和之前所说一样，还是人类社会组织存续能力的问题，也就是政治学范畴的问题。<br>
这锅，不能让技术来背。</p>
<p>依赖高科技、自动化的社会非常脆弱吗？<br>
原文中举飞机的飞行控制软件的例子并不妥当。<br>
飞机商用之前会经过严格的测试和试飞，必要时也有高科技、自动化之外的人工干预手段。<br>
因此软件出现问题导致飞机坠毁的概率微乎其微。<br>
而且越是了解飞行的人，越清楚飞行没有百分之百的安全，能够接受事故概率而坐上飞机的人，不会对这种问题盲目恐惧。</p>
<p>如果回到人类社会上，也就是说，人类的存在和发展本来就不是天经地义、百分之百安全。<br>
技术是人类对抗残酷的大自然的手段之一，技术发展到今天，正是人类社会自我保存和发展的需求所驱动的。<br>
为了未来未知的技术风险，忽视当下无时无刻不在涌现的实际需求，不是因噎废食、杞人忧天是什么呢？<br>
就是不知道不知道这是身为技术人员的阮一峰的真实想法，还是为了推广书而故意为之的宣传策略了。</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
