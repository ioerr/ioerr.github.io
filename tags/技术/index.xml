<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技术 on 读写错误</title>
    <link>https://ioerr.github.io/tags/%E6%8A%80%E6%9C%AF/</link>
    <description>Recent content in 技术 on 读写错误</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 08 Dec 2018 00:00:00 +0000</lastBuildDate>
    
      <atom:link href="https://ioerr.github.io/tags/%E6%8A%80%E6%9C%AF/index.xml" rel="self" type="application/rss+xml" />
    
    
      <item>
        <title>不要恐慌</title>
        <link>https://ioerr.github.io/posts/dont-panic/</link>
        <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
        <author>
            <name>Calon</name>
            <uri>https://twitter.com/calon</uri>
            <email>calon.xu@gmail.com</email>
        </author>
        <guid>https://ioerr.github.io/posts/dont-panic/</guid>
        <description>&lt;p&gt;最近在同时阅读四个人的作品，看上去风马牛不相及，但又有内在的关联：&lt;/p&gt;

&lt;p&gt;阮一峰的《未来世界的幸存者》；&lt;br /&gt;
卡钦斯基（Theodore Kaczynski）的长文《论工业社会及其未来》；&lt;br /&gt;
冯象的《我是阿尔法》；&lt;br /&gt;
德鲁克（Peter Drucker）的《经济人的末日》、《工业人的未来》、《公司的概念》、《新社会》等等。&lt;/p&gt;

&lt;p&gt;他们的共同点是认识到科学技术——计算机、互联网、人工智能、大数据、基因编辑…任何资本主义大规模工业生产活动及其成果——已经和将会对人类社会产生前所未有冲击，重构、颠覆人类社会，乃至经过自然演化发展到今天的人类这种生物。&lt;/p&gt;

&lt;p&gt;不同点在于，他们想到的应对解决方案可谓完全不同。&lt;/p&gt;

&lt;p&gt;阮一峰的建议主要在个人层面，如加强个人的学习教育投入，鼓励创业创新，做好职业和人生规划，争取成为未来的高级人类那一小拨。&lt;br /&gt;
但在宏观层面没有什么想法。他表达了和卡钦斯基一样的担忧，认为技术发展可能会导致人类社会脆弱和丧失自由，但也只能沿着看不清楚的技术之路继续走下去。&lt;/p&gt;

&lt;p&gt;卡钦斯基的文章则直言工业社会的未来只可能是被体系奴役或全面崩溃，工业社会的体系要么被一小群精英掌握，要么人类彻底依赖于机器，个人要么因为工业社会造成的严重的心理和生理问题被淘汰掉，要么被体系当作无用的个体清除掉，要么丧失自由成为体系的奴隶。当体系持续运转时，个体承受的痛苦超过之前的社会体系，而当体系无法持续运转时，整个社会将会崩溃并倒退回工业时代之前的野蛮战争状态。&lt;br /&gt;
他给出的方案和实际执行的行动是，在来得及退出工业社会的死胡同之时，放弃依赖大规模社会组织的技术发展，为之不惜采用暴力恐怖袭击。&lt;/p&gt;

&lt;p&gt;冯象认为资本主义社会无法解决贫富差距扩大、技术进步带来的大失业、福利制度无以为继、生产依赖机器、大企业全面支配控制个人等问题，于是从人工智能和法学的关系切入，认为未来人工智能将作为政府监管社会的强力工具，介入处理人类的法律事务，并将私法问题转化为公法问题，将市场经济转化为计划经济，最终干预人类的政治活动，成为超越人类之上的更高智慧。它可能带来生产力的大飞跃，可能圈养或灭绝人类，也有可能在私有制度下被私人企业用于违法活动、寡头垄断和战争，走上失控之路。&lt;br /&gt;
他给出的药方是，不允许个人和私人企业发展、维护人工智能技术，收归国有，发展到高级阶段则经济全面公有化，国家统一监督计划人工智能的应用。以及，在资本主义制度下，发展到机器人消灭劳动分工，带来大失业，使全人类一律变成机器的附属品，私人财富没有意义时，顺理成章地取消私有制度，走向共产主义。同时，向演化出自我意识的机器人灌输为人民服务的先进性思想和“毫不利己，专门利人”的共产主义道德，让它承担起爱护人类的积极义务，与人类和谐共处，最终实现共产主义。&lt;/p&gt;

&lt;p&gt;德鲁克的几本书而且写作出版的年代最久远，但其深度和广度乃至洞察力却是上述三人的文章不可比拟的。&lt;br /&gt;
他在计算机和人工智能大规模应用之前就认识到了大规模工业生产对人类社会的影响，既没有被法西斯和极权主义的组织概念蒙骗，也不像卡钦斯基那样对工业社会的未来悲观绝望，更不像乌托邦信徒一样为了追求理念中的自由而选择抽掉经济基础的激进手段。&lt;br /&gt;
在德鲁克看来，工业人的身份、企业作为社会组织的功能和责任、社会的全新秩序是工业社会继续发展必须要重新界定和整合的。而且这一过程直到今天依然还在继续，这一人类历史上最深远的社会转型带来的阵痛不应该是因噎废食或病急乱投医的理由。&lt;/p&gt;

&lt;p&gt;虽然我还没有全部读完德鲁克的这几本书，但他对大企业和工业社会弊病症结的精彩分析，对社会组织结构彻底变革的乐观，对人的自由、尊严、想象力和创造力的尊重和信心，贯穿始终，没有焦虑和恐慌，积极面对未来的问题，这种阅读的感觉很好。&lt;br /&gt;
等到全部读完了，再来一篇总结吧。&lt;/p&gt;

&lt;p&gt;话说回来，尽管上述几个作者写作的初衷之一是担忧人类被机器人取代，但也许这事其实并没那么可怕，完全不用恐慌。&lt;br /&gt;
现实当中许多人根本不在乎自己和其他人被自己的同类奴役、豢养、牺牲和屠杀，换成让未来机器人干这个事情，也许他们还要为机器人的高效率而欢欣鼓舞呢。&lt;/p&gt;
</description>
      </item>
    
      <item>
        <title>Gattaca</title>
        <link>https://ioerr.github.io/posts/gattaca/</link>
        <pubDate>Tue, 27 Nov 2018 00:00:00 +0000</pubDate>
        <author>
            <name>Calon</name>
            <uri>https://twitter.com/calon</uri>
            <email>calon.xu@gmail.com</email>
        </author>
        <guid>https://ioerr.github.io/posts/gattaca/</guid>
        <description>&lt;p&gt;Ethan Hawke、Uma Thurman 和 Jude Law 于1997年出演的电影《Gattaca》在我心目中可以排在科幻电影前三位。&lt;br /&gt;
主流电影中讨论基因改造话题的不算多，《Gattaca》想象了基因改造技术对人类社会和个体的影响，以及基因和命运不如他人完美的个人如何挑战被基因决定的未来和追求毕生理想。&lt;br /&gt;
剧情、演技、节奏、画面风格（当前时间线的日间都是昏黄的特殊色调）、音乐（强烈推荐）都相当出色。&lt;/p&gt;

&lt;p&gt;可惜限于篇幅，电影只是展示了两位主人公的命运起伏，而且让其中一位开了挂，另外只用较小的篇幅提到了“劣等基因”阶层的生存状况。&lt;br /&gt;
如果能更加深入地探讨基因改造造成社会阶层隔离的后续如何发展，就可以在我心目中排到第一了。&lt;br /&gt;
我就想看看，如果按基因编辑人种就是在各方面超过自然生育进化的人种来推想，最终社会会发展成为什么样子。&lt;br /&gt;
不要有逆天的主角靠意志突破先天的优势壁垒，不要像某些超能力英雄一样跑出来说能力越大责任越大——蜘蛛侠也好，X Man 也好，真出现了这样能力远远超过常人的存在，我反正不会寄希望于毫无约束的至善人性，会始终主动冒着生命危险保护弱者。&lt;/p&gt;

&lt;p&gt;不过如果继续深入挖掘这个题材，也许需要扩充为电视剧集的长度才行，这几年连《西部世界》都翻拍和扩充成为电视剧集，《Gattaca》应该也可以享受这个待遇吧。&lt;/p&gt;

&lt;p&gt;为什么忽然想到《Gattaca》呢，因为基因技术改造人类带来的影响在我们这一辈就快要不是科幻话题了。&lt;br /&gt;
&lt;a href=&#34;http://www.zhishifenzi.com/news/multiple/4667.html&#34;&gt;世界首例基因编辑婴儿露露和娜娜在中国诞生&lt;/a&gt;，全球首例基因编辑人体试验已经成为事实，在学界和社会掀起了轩然大波。&lt;/p&gt;

&lt;p&gt;目前学界争论的焦点是一系列现实问题：试验是否成功，是否遵循了伦理原则，是否让试验对象承受了不必要的风险，试验对象的个人权利如何保障？&lt;br /&gt;
试验项目负责人贺建奎的激进冒险，将反对基因编辑技术和希望技术稳步前进的两群人，以及持这两种态度的公众，都一下子推到了对立面。&lt;br /&gt;
短期内，类似的试验会更加严格限制，甚至因为公众的恐惧而大大降低民众对科学团体的信任，影响正常的技术发展和试验开展。&lt;/p&gt;

&lt;p&gt;然而，应该看到，基因编辑的技术突破和应用是不可阻挡的趋势，不可能永远限制住——事实已经证明，现在就很难限制住了。&lt;br /&gt;
基因工程不像基础物理试验，相对较低的预算也可以拉出小团队悄悄地甩开伦理审查弄地下试验，又有足够的利益驱动，所以我很不看好靠伦理审查能够挡住这类技术应用。&lt;br /&gt;
短期内只能寄希望于技术不够成熟，效果还不理想，希望应用基因编辑的买家持续观望。&lt;br /&gt;
长期来看，虽然现在人类对基因片段和基因组生效的效果和机制还不甚了了，基因编辑手段也不够成熟，但这只是时间问题。只要技术有理论可能和应用的需求前景，就一定会被发展出来投入使用并不断优化，到那个时候，有需求有供给能力，就很难禁绝。&lt;br /&gt;
我们能做的，除了努力使基因编辑技术的发展尽量降低风险和争议，在可控中前进，也要开始从心理和制度上慢慢适应可能会出现新型人类的社会了。&lt;/p&gt;

&lt;p&gt;许多人害怕应用基因编辑技术定制新型人类，其实不是关心伦理问题——医学伦理和人类定义的哲学问题他们既不了解也不关心，主要是担心财富和资源的多寡从出生开始就可以拉开不同阶层的身体硬件条件上的鸿沟，这进一步加剧了当前社会对阶层彻底固化的焦虑。&lt;/p&gt;

&lt;p&gt;有的人认为，基因编辑技术会像历史上所有的民用级技术一样，在成熟和推广开来后，成本不断降低，市场不断扩大，最终总会从富人的玩具变成平民的日用品，不会成为富人的专利。&lt;br /&gt;
但毕竟谁也不能打包票说未来就会如此发展，特别是基因编辑改变的是底层的硬件参数，其影响和过去的技术进步不可同日而语。&lt;/p&gt;

&lt;p&gt;最可能的糟糕结果，就是有资格应用基因编辑技术的少数人，利用短期内形成的智力和体力优势壁垒，形成对其余大多数人的彻底压制，最终演变成永恒的奴隶主和奴隶阶层，或者干脆变成高阶新人类与低阶旧人类的对立。&lt;br /&gt;
这在科幻作品和社会制度批判方面是非常常见的观点，但我们通常看到的都是如何避免这种情况出现，而不是一旦真的形成这种人种级别的压制优势，被压制的旧人类、低级阶层一方是否还有翻身、争取对等地位和维持生存的可能？&lt;/p&gt;

&lt;p&gt;掌握了基因技术之后，人类最舍不得放弃的恐怕就是寿命了。&lt;br /&gt;
其他方面都可以依靠基因编辑不断优化，但断不会有人故意负“优化”自身的寿命，否则就把自己变成了银翼杀手中的人造人。&lt;br /&gt;
高阶新人类唯一的弱点也许就在于此。理解了达尔文演化论的人明白，长寿是个体所追求的，但对物种而言说不上绝对的好坏。&lt;/p&gt;

&lt;p&gt;也许今后无法用上基因编辑技术的低阶旧人类在灭绝之前，会为环境所迫发展成为大量繁殖、快速死亡和演化的新物种。&lt;br /&gt;
（当然，虽然不能应用基因编辑技术，却必须要能通过其他技术快速传承知识，维持智力上的差距不被拉得太大。）&lt;br /&gt;
就像奇幻小说中，人类相对于精灵族一样，短寿、低能、野蛮，但繁殖和适应能力优越，成为高级病毒。&lt;/p&gt;

&lt;p&gt;一旦高阶人类这种长寿物种自身迭代的速度赶不上低阶人类不惜短寿快速迭代的速度，也许后者才有些许胜机或生机。&lt;/p&gt;

&lt;p&gt;要么就是，因为拼命抗拒死亡的规律，超出合理程度的长寿，带来资源短缺和争抢，无法在社会制度层面解决资源重新分配的问题，从而导致内战和崩溃。但低阶旧人类能否从中获利还很难说。&lt;/p&gt;

&lt;p&gt;或者，是基因改造方向大量趋同，导致基因库多样性严重下降，被未能预料到的自然界危机一波消灭。&lt;br /&gt;
但我相信以新人类经过提升的智力，还不至于犯这么低级的错误。&lt;/p&gt;

&lt;p&gt;当然，也有可能高阶新人类迅速灭绝或放逐了低阶旧人类，杜绝了任何翻盘的可能，就像智人消灭了所有的近亲物种，成为这一支上的独苗。&lt;br /&gt;
作为旧人类的一员，最好还是祈祷以上多种可能晚一点成真吧。&lt;/p&gt;
</description>
      </item>
    
      <item>
        <title>我为什么反对卢德主义</title>
        <link>https://ioerr.github.io/posts/wo-weishenme-fandui-luddism/</link>
        <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
        <author>
            <name>Calon</name>
            <uri>https://twitter.com/calon</uri>
            <email>calon.xu@gmail.com</email>
        </author>
        <guid>https://ioerr.github.io/posts/wo-weishenme-fandui-luddism/</guid>
        <description>&lt;p&gt;工业革命初期，失业的工人认为他们被机器抢走了工作机会，于是捣毁机器，他们被称为卢德主义者。&lt;/p&gt;

&lt;p&gt;随着工业革命继续进行，人们认识到机器取代低效的人力不可避免，卢德主义慢慢不再有号召力。&lt;/p&gt;

&lt;p&gt;到了计算机时代，新的卢德主义者们担忧计算机和人工智能会胜过和取代人类，许多科学家和计算机业界的知名人士也呼吁停止人工智能发展。&lt;/p&gt;

&lt;p&gt;我可以理解卢德主义者担忧技术快速发展带来的结构性失业问题，但不认为停止技术发展是解决该问题的好办法——无论从历史经验还是经济学理论来看，卢德主义都找错了问题的原因，表面看是技术带来的问题，归根结底还是经济和政治问题，其解决方案因此也站不住脚。&lt;/p&gt;

&lt;p&gt;我也认同未来的强人工智能的确有胜过、取代、奴役和消灭人类的危险，但从价值观出发，我强烈反感卢德主义——因为卢德主义代表最反对人类价值的观点。&lt;/p&gt;

&lt;p&gt;生命的价值和尊严在于生存本身，还是其创造的价值？&lt;br /&gt;
你是根据一个人生存状况还是他创造的东西来评价他？&lt;br /&gt;
这就是技术发展问题背后的价值观差异。&lt;/p&gt;

&lt;p&gt;在我看来，人类之所以为人类，区别于其他已知的生物，是因为人类会为了生存繁衍之上的理想和目标运用理性思考和技术工具，不断有目的、有意识地发明创造和改变世界，而不只是为了在残酷的环境中苟且偷生。&lt;/p&gt;

&lt;p&gt;如果人类没有超越世界给定的追求目标，那么无论生活如何富足舒适，和无智慧的生物又有什么本质区别？&lt;/p&gt;

&lt;p&gt;人工智能等计算机技术的发展，既是大幅度提升技术工具的生产力，也是对人类自身智慧机理的深入探索方式之一，更是突破自然界演化结果的尝试和挑战：突破碳基生命智慧上限，甚至与人工智慧并存形成新形态的生命形式。&lt;/p&gt;

&lt;p&gt;计算机时代的新卢德主义，则是在“人类的安全”和“人类成为更高维度智慧生命”之间，坚定认为为了前者的缘故，必须牺牲后者的机会——即使技术的发展未必就会毁灭人类，人类社会的问题也未必来自于技术发展，更不用说未来也许只有依靠新技术才能应对星球级别的天灾。&lt;/p&gt;

&lt;p&gt;曾经的地壳霸主恐龙统治地球表面超过1亿6千万年，人类站到食物链顶端的时间还差得远，但如果坚持卢德主义，失去技术发展带来的无限可能，那么人类的未来与恐龙将没有区别。&lt;/p&gt;

&lt;p&gt;另：最近看到冯象的《我是阿尔法》和阮一峰的《未来世界的幸存者》都表达了对机器取代人类的担忧，以及为了避免这种结局而停止技术发展的倾向。&lt;br /&gt;
这方面最值得说道的应该是 Kaczynski 的《工业社会及其未来》，事迹影响大，中文读者相对比较熟悉，一些对未来技术发展的思考可以引出不少有意思的话题，后续可以写个系列出来。&lt;/p&gt;
</description>
      </item>
    
      <item>
        <title>现代杞人忧天</title>
        <link>https://ioerr.github.io/posts/xiandai-qirenyoutian/</link>
        <pubDate>Wed, 29 Mar 2017 12:11:30 +0800</pubDate>
        <author>
            <name>Calon</name>
            <uri>https://twitter.com/calon</uri>
            <email>calon.xu@gmail.com</email>
        </author>
        <guid>https://ioerr.github.io/posts/xiandai-qirenyoutian/</guid>
        <description>&lt;p&gt;阮一峰最近在&lt;a href=&#34;www.ruanyifeng.com/blog/2017/03/boundary.html&#34;&gt;《技术的边界》&lt;/a&gt;中提到一个不算新鲜的观点：技术高速发展所蕴含的巨大能量，最终将把人类社会带到难以预测的脆弱状态。&lt;/p&gt;

&lt;p&gt;其逻辑要点是：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;系统越来越复杂，分工越来越细，大多数人已经不能够理解技术了，一个人也不可能从头到尾掌握整个系统。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;因为无法理解技术，人类不知道今后技术会突破到什么程度。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;只要技术有能力做到的事情，最终都会做到。人类没有办法遏制它的发展。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;无法理解和无法控制发展，因此人类无法控制新技术的后果，可能实现能摧毁文明的技术。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;结论：依赖技术的高科技、高度自动化的社会非常脆弱。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我觉得这完全是现代版的杞人忧天：&lt;/p&gt;

&lt;p&gt;细致分工导致隔行如隔山、一个人无法掌握整个系统，不是大问题。&lt;br /&gt;
只要人类的沟通、交流、利益驱动、组织能力还在，分别掌握了技术细节的人可以随时组织起来，重建技术文明。&lt;br /&gt;
而且历史证明，行业分工合作的社会，其竞争力远超没有分工的社会，从头再来仍然还会是这个结果，从分工导致的现象开始担忧没有道理。&lt;/p&gt;

&lt;p&gt;人类无法预测技术的未来发展也不是大问题。&lt;br /&gt;
事实上人类从来就没有搞清楚技术的未来在什么方向，只是技术进步的速度加快，让现代人普遍能体会到这种对未来的无知。&lt;br /&gt;
我看到有网友评论得好：这种担忧只是人类对未知的原始本能的恐惧。&lt;/p&gt;

&lt;p&gt;技术上能够实现的事情最终都会实现也不是大问题。&lt;br /&gt;
这种表述方式有点像 Kevin Kelly 的《What Technology Wants》中将技术视为某种生命存在方式，或者盖亚假说中将整个地球生态视为有意识有目的的生命。&lt;br /&gt;
仿佛冥冥之中人类会不由自主地为技术这种生命形式的目的服务。&lt;br /&gt;
但实际上决定某项技术能否实现的，归根到底是人类的需求。&lt;/p&gt;

&lt;p&gt;我们看到的许多实现难度很高或者为主流社会不容的技术突破，都是因为有人类需求源源不断地驱动。&lt;br /&gt;
这需求不止是要用真金白银兑现的市场需求，也包括人类天生好奇心所催生的不求回报的需求。&lt;br /&gt;
而同时，还有海量的本可能实现，但因为缺少需求驱动而胎死腹中、脑中的潜在的技术突破点，根本不需要妄图阻止技术进步的卢德主义者出手，就默默无闻地消失在历史长河中了，而我们只能看到那些突破重重险阻实现了的。&lt;br /&gt;
一旦落到人类自身需求的层面上来，对技术发展的担忧就转变为对人类社会组织存续能力的担忧。&lt;/p&gt;

&lt;p&gt;新技术不可控的问题那得看是对谁而言。&lt;br /&gt;
如果你是希望全局掌控社会发展动态的控制狂，那么这确实是大问题。&lt;br /&gt;
但如果你明白社会竞争发展的常态本来就是一种“基本可控的不可控”状态，那么这也不是什么大问题。&lt;/p&gt;

&lt;p&gt;要担心的是能够一下子毁灭所有人类的技术被某个漠视现世价值的疯子掌握，或者技术发展导致人类的演变出现严重撕裂社会进而引起世界战争的情况。&lt;br /&gt;
但这也不是技术层面的问题，和之前所说一样，还是人类社会组织存续能力的问题，也就是政治学范畴的问题。&lt;br /&gt;
这锅，不能让技术来背。&lt;/p&gt;

&lt;p&gt;依赖高科技、自动化的社会非常脆弱吗？&lt;br /&gt;
原文中举飞机的飞行控制软件的例子并不妥当。&lt;br /&gt;
飞机商用之前会经过严格的测试和试飞，必要时也有高科技、自动化之外的人工干预手段。&lt;br /&gt;
因此软件出现问题导致飞机坠毁的概率微乎其微。&lt;br /&gt;
而且越是了解飞行的人，越清楚飞行没有百分之百的安全，能够接受事故概率而坐上飞机的人，不会对这种问题盲目恐惧。&lt;/p&gt;

&lt;p&gt;如果回到人类社会上，也就是说，人类的存在和发展本来就不是天经地义、百分之百安全。&lt;br /&gt;
技术是人类对抗残酷的大自然的手段之一，技术发展到今天，正是人类社会自我保存和发展的需求所驱动的。&lt;br /&gt;
为了未来未知的技术风险，忽视当下无时无刻不在涌现的实际需求，不是因噎废食、杞人忧天是什么呢？&lt;br /&gt;
就是不知道不知道这是身为技术人员的阮一峰的真实想法，还是为了推广书而故意为之的宣传策略了。&lt;/p&gt;
</description>
      </item>
    
  </channel>
</rss>
