<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技术 on 读写错误</title>
    <link>https://ioerr.github.io/tags/%E6%8A%80%E6%9C%AF/</link>
    <description>Recent content in 技术 on 读写错误</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 19 Aug 2018 00:00:00 +0000</lastBuildDate>
    
      <atom:link href="https://ioerr.github.io/tags/%E6%8A%80%E6%9C%AF/index.xml" rel="self" type="application/rss+xml" />
    
    
      <item>
        <title>我为什么反对卢德主义</title>
        <link>https://ioerr.github.io/posts/wo-weishenme-fandui-luddism/</link>
        <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
        <guid>https://ioerr.github.io/posts/wo-weishenme-fandui-luddism/</guid>
        <description>&lt;p&gt;工业革命初期，失业的工人认为他们被机器抢走了工作机会，于是捣毁机器，他们被称为卢德主义者。&lt;/p&gt;

&lt;p&gt;随着工业革命继续进行，人们认识到机器取代低效的人力不可避免，卢德主义慢慢不再有号召力。&lt;/p&gt;

&lt;p&gt;到了计算机时代，新的卢德主义者们担忧计算机和人工智能会胜过和取代人类，许多科学家和计算机业界的知名人士也呼吁停止人工智能发展。&lt;/p&gt;

&lt;p&gt;我可以理解卢德主义者担忧技术快速发展带来的结构性失业问题，但不认为停止技术发展是解决该问题的好办法——无论从历史经验还是经济学理论来看，卢德主义都找错了问题的原因，表面看是技术带来的问题，归根结底还是经济和政治问题，其解决方案因此也站不住脚。&lt;/p&gt;

&lt;p&gt;我也认同未来的强人工智能的确有胜过、取代、奴役和消灭人类的危险，但从价值观出发，我强烈反感卢德主义——因为卢德主义代表最反对人类价值的观点。&lt;/p&gt;

&lt;p&gt;生命的价值和尊严在于生存本身，还是其创造的价值？&lt;br /&gt;
你是根据一个人生存状况还是他创造的东西来评价他？&lt;br /&gt;
这就是技术发展问题背后的价值观差异。&lt;/p&gt;

&lt;p&gt;在我看来，人类之所以为人类，区别于其他已知的生物，是因为人类会为了生存繁衍之上的理想和目标运用理性思考和技术工具，不断有目的、有意识地发明创造和改变世界，而不只是为了在残酷的环境中苟且偷生。&lt;/p&gt;

&lt;p&gt;如果人类没有超越世界给定的追求目标，那么无论生活如何富足舒适，和无智慧的生物又有什么本质区别？&lt;/p&gt;

&lt;p&gt;人工智能等计算机技术的发展，既是大幅度提升技术工具的生产力，也是对人类自身智慧机理的深入探索方式之一，更是突破自然界演化结果的尝试和挑战：突破碳基生命智慧上限，甚至与人工智慧并存形成新形态的生命形式。&lt;/p&gt;

&lt;p&gt;计算机时代的新卢德主义，则是在“人类的安全”和“人类成为更高维度智慧生命”之间，坚定认为为了前者的缘故，必须牺牲后者的机会——即使技术的发展未必就会毁灭人类，人类社会的问题也未必来自于技术发展，更不用说未来也许只有依靠新技术才能应对星球级别的天灾。&lt;/p&gt;

&lt;p&gt;曾经的地壳霸主恐龙统治地球表面超过1亿6千万年，人类站到食物链顶端的时间还差得远，但如果坚持卢德主义，失去技术发展带来的无限可能，那么人类的未来与恐龙将没有区别。&lt;/p&gt;

&lt;p&gt;另：最近看到冯象的《我是阿尔法》和阮一峰的《未来世界的幸存者》都表达了对机器取代人类的担忧，以及为了避免这种结局而停止技术发展的倾向。&lt;br /&gt;
这方面最值得说道的应该是 Kaczynski 的《工业社会及其未来》，事迹影响大，中文读者相对比较熟悉，一些对未来技术发展的思考可以引出不少有意思的话题，后续可以写个系列出来。&lt;/p&gt;
</description>
      </item>
    
      <item>
        <title>现代杞人忧天</title>
        <link>https://ioerr.github.io/posts/xiandai-qirenyoutian/</link>
        <pubDate>Wed, 29 Mar 2017 12:11:30 +0800</pubDate>
        <guid>https://ioerr.github.io/posts/xiandai-qirenyoutian/</guid>
        <description>&lt;p&gt;阮一峰最近在&lt;a href=&#34;www.ruanyifeng.com/blog/2017/03/boundary.html&#34;&gt;《技术的边界》&lt;/a&gt;中提到一个不算新鲜的观点：技术高速发展所蕴含的巨大能量，最终将把人类社会带到难以预测的脆弱状态。&lt;/p&gt;

&lt;p&gt;其逻辑要点是：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;系统越来越复杂，分工越来越细，大多数人已经不能够理解技术了，一个人也不可能从头到尾掌握整个系统。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;因为无法理解技术，人类不知道今后技术会突破到什么程度。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;只要技术有能力做到的事情，最终都会做到。人类没有办法遏制它的发展。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;无法理解和无法控制发展，因此人类无法控制新技术的后果，可能实现能摧毁文明的技术。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;结论：依赖技术的高科技、高度自动化的社会非常脆弱。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我觉得这完全是现代版的杞人忧天：&lt;/p&gt;

&lt;p&gt;细致分工导致隔行如隔山、一个人无法掌握整个系统，不是大问题。&lt;br /&gt;
只要人类的沟通、交流、利益驱动、组织能力还在，分别掌握了技术细节的人可以随时组织起来，重建技术文明。&lt;br /&gt;
而且历史证明，行业分工合作的社会，其竞争力远超没有分工的社会，从头再来仍然还会是这个结果，从分工导致的现象开始担忧没有道理。&lt;/p&gt;

&lt;p&gt;人类无法预测技术的未来发展也不是大问题。&lt;br /&gt;
事实上人类从来就没有搞清楚技术的未来在什么方向，只是技术进步的速度加快，让现代人普遍能体会到这种对未来的无知。&lt;br /&gt;
我看到有网友评论得好：这种担忧只是人类对未知的原始本能的恐惧。&lt;/p&gt;

&lt;p&gt;技术上能够实现的事情最终都会实现也不是大问题。&lt;br /&gt;
这种表述方式有点像 Kevin Kelly 的《What Technology Wants》中将技术视为某种生命存在方式，或者盖亚假说中将整个地球生态视为有意识有目的的生命。&lt;br /&gt;
仿佛冥冥之中人类会不由自主地为技术这种生命形式的目的服务。&lt;br /&gt;
但实际上决定某项技术能否实现的，归根到底是人类的需求。&lt;/p&gt;

&lt;p&gt;我们看到的许多实现难度很高或者为主流社会不容的技术突破，都是因为有人类需求源源不断地驱动。&lt;br /&gt;
这需求不止是要用真金白银兑现的市场需求，也包括人类天生好奇心所催生的不求回报的需求。&lt;br /&gt;
而同时，还有海量的本可能实现，但因为缺少需求驱动而胎死腹中、脑中的潜在的技术突破点，根本不需要妄图阻止技术进步的卢德主义者出手，就默默无闻地消失在历史长河中了，而我们只能看到那些突破重重险阻实现了的。&lt;br /&gt;
一旦落到人类自身需求的层面上来，对技术发展的担忧就转变为对人类社会组织存续能力的担忧。&lt;/p&gt;

&lt;p&gt;新技术不可控的问题那得看是对谁而言。&lt;br /&gt;
如果你是希望全局掌控社会发展动态的控制狂，那么这确实是大问题。&lt;br /&gt;
但如果你明白社会竞争发展的常态本来就是一种“基本可控的不可控”状态，那么这也不是什么大问题。&lt;/p&gt;

&lt;p&gt;要担心的是能够一下子毁灭所有人类的技术被某个漠视现世价值的疯子掌握，或者技术发展导致人类的演变出现严重撕裂社会进而引起世界战争的情况。&lt;br /&gt;
但这也不是技术层面的问题，和之前所说一样，还是人类社会组织存续能力的问题，也就是政治学范畴的问题。&lt;br /&gt;
这锅，不能让技术来背。&lt;/p&gt;

&lt;p&gt;依赖高科技、自动化的社会非常脆弱吗？&lt;br /&gt;
原文中举飞机的飞行控制软件的例子并不妥当。&lt;br /&gt;
飞机商用之前会经过严格的测试和试飞，必要时也有高科技、自动化之外的人工干预手段。&lt;br /&gt;
因此软件出现问题导致飞机坠毁的概率微乎其微。&lt;br /&gt;
而且越是了解飞行的人，越清楚飞行没有百分之百的安全，能够接受事故概率而坐上飞机的人，不会对这种问题盲目恐惧。&lt;/p&gt;

&lt;p&gt;如果回到人类社会上，也就是说，人类的存在和发展本来就不是天经地义、百分之百安全。&lt;br /&gt;
技术是人类对抗残酷的大自然的手段之一，技术发展到今天，正是人类社会自我保存和发展的需求所驱动的。&lt;br /&gt;
为了未来未知的技术风险，忽视当下无时无刻不在涌现的实际需求，不是因噎废食、杞人忧天是什么呢？&lt;br /&gt;
就是不知道不知道这是身为技术人员的阮一峰的真实想法，还是为了推广书而故意为之的宣传策略了。&lt;/p&gt;
</description>
      </item>
    
  </channel>
</rss>
