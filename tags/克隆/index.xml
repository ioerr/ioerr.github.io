<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>克隆 on 读写错误</title>
    <link>https://ioerr.github.io/tags/%E5%85%8B%E9%9A%86/</link>
    <description>Recent content in 克隆 on 读写错误</description>
    <generator>Hugo -- 0.126.0</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 08 Mar 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://ioerr.github.io/tags/%E5%85%8B%E9%9A%86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>恐惧不是生存之道</title>
      <link>https://ioerr.github.io/posts/kongju-bushi-qiusheng-zhi-dao/</link>
      <pubDate>Wed, 08 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/kongju-bushi-qiusheng-zhi-dao/</guid>
      <description>Tinyfool 和不明白播客录制了一期《ChatGPT 会如何改变我们的生活？》，结尾的核心观点是：科技不应该是被恐惧的东西，而是要被拥有的东西。 我最近一直</description>
      <content:encoded><![CDATA[<p><a href="https://twitter.com/tinyfool">Tinyfool</a> 和<a href="https://www.bumingbai.net/">不明白播客</a>录制了一期《<a href="https://www.bumingbai.net/2023/02/ep-037-tinyfool-text/">ChatGPT 会如何改变我们的生活？</a>》，结尾的核心观点是：科技不应该是被恐惧的东西，而是要被拥有的东西。</p>
<blockquote>
<p>我最近一直有在形成一个新的观点，就是技术呢，它的发展是不可阻挡的。基本上张三不发明，李四就发明；牛顿不做微积分，莱布尼茨也要做，甚至两个人一块儿做。那这些东西，它有它本质的关联。就是说当这个技术发明了，下一个技术可能就已经在路上了。但是问题出在哪儿呢？问题出在，我认为以前我们常用的话，“技术是双刃剑”是错的。问题出在技术不断在前进，而人也需要进化。人需要发展出新的理论去面对手里更厉害的武器。而不是去抱怨说这个东西怎么那么强大，它能不能用来害我？因为它的进步是无法阻挡，所以你就必须得去掌握它，你得让它变成一个好的东西。<br>
我们今天看了很多科幻都是那种，比方说赛博朋克那种东西，它都是对未来宇宙很黑暗的理解，包括我们对核武器的理解都很灰暗。我认为这些想法都是对的，但是最终这些想法要回到怎么去提供一个方案，让我们既拥有了科技文明带来的好处，又去避免它有可能的坏处。今天对于ChatGPT我也是这么想的。这个AI，你想拿它去做一些垃圾内容，完全没问题，你想拿它去做一些坏事，完全没有问题。做坏事的人看到这个东西，他也是高兴得要命。但是你想让人们的生活变得更美好，你想让这个世界变革，也是需要这样的东西。<br>
所以我很庆幸，包括有一句话，听着可能有些观众就不太喜欢了：我喜欢的这个社会，它应该不断地有科技进步，这样所有的文明都会想，我们应该开放应该包容，应该允许大家去创新。如果这个世界科技突然停止了，那OK了，那copy to China就赢了，因为你是静止的，那就看谁抄得快嘛。但是这个世界正好一步一步地证明，你抄得再快也没有用，因为世界在不停地在进步。所以我希望所有的各种进步不断地改变人类，希望人类去提升自己的文化能力，对世界的理解，我们去应对这个更牛逼的世界。不是说有一天AI、强AI出来以后，我们吓得四散奔逃，而是我们发现因为我们也变得非常伟大，而强AI只能是我们的朋友，只能辅助我们，这才是未来。我觉得科技不应该是被恐惧的东西，而是要被拥有的东西。</p>
</blockquote>
<p>有人问，对修改基因技术和克隆技术怎么看？</p>
<p>我的观点是：<br>
这些迟早会成为普及的技术，但如何让我们的伦理道德和社会制度适应、接纳，需要走很长一段路。<br>
学界也知道靠堵是堵不住的，但观念的改变不是一朝一夕的事情，必然会有巨大的冲击震动。<br>
这种适应和接纳不是一味的纵容，而是有配套的社会制度变化、伦理规范调整、心理转变。<br>
奴隶制消亡、封建帝制终结、女性平权、同性恋婚姻等等都掀起了轩然大波，何况这种动摇生物基础和社会基本观念的变化，没个几百年不会消停。</p>
<p>有人好奇，就算AI比人类推演强一万倍，谁有那个胆子真的把军队交给AI控制吗？<br>
如果真能做到军队无人化，所有坦克飞机军舰甚至士兵都是AI控制的无人机，那么万一……AI一翻脸……？</p>
<p>如果你的对手将部分武装交给AI管理，结果打得你屁滚尿流，你会不会学他？<br>
如果到最后谁让AI介入越多谁就能赢，你说会不会都用上AI？<br>
竞争这东西不是你想摆脱就摆脱的。</p>
<hr>
<p><a href="https://twitter.com/Soulogic/status/1608499943408533504">Soulogic</a>：<br>
杰克·伦敦身强力壮，一个人干了两个人的工，其中一个被他顶掉的工人后来自杀了<br>
可能大家没想那么多、没那么邪恶，但这个话题在我这是个敏感的政治正确禁忌：<br>
不要讨论在狮子面前如何跑得比别人快，不快跑的 loser 活该被吃。<br>
作为角斗士我支持奴隶制，因为我能打赢</p>
<p>全世界无产者，联合起来！</p>
<hr>
<p>在我看来，这还是一种现代卢德主义。<br>
竞争无处不在，技术进步干掉人工是不可阻挡的趋势，而且技术迭代的速度越快，被替代者适应的难度越高。<br>
就像生物说“我不支持进化论”，不表示就能摆脱进化的规律。<br>
<a href="../zhishi-da-rongtong">进步棘轮</a>和红皇后效应避无可避。<br>
能够做的是如何更合理地保护被替代的个体，平复阵痛，找到创新方向提升长远的竞争力。<br>
人类文明发展到今天，早就在观念上跨过了失败者只能去死的阶段。</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
