<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>失业 on 读写错误</title>
    <link>https://ioerr.github.io/tags/%E5%A4%B1%E4%B8%9A/</link>
    <description>Recent content in 失业 on 读写错误</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 08 Dec 2018 00:00:00 +0000</lastBuildDate>
    
      <atom:link href="https://ioerr.github.io/tags/%E5%A4%B1%E4%B8%9A/index.xml" rel="self" type="application/rss+xml" />
    
    
      <item>
        <title>不要恐慌</title>
        <link>https://ioerr.github.io/posts/dont-panic/</link>
        <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
        <author>
            <name>Calon</name>
            <uri>https://twitter.com/calon</uri>
            <email>calon.xu@gmail.com</email>
        </author>
        <guid>https://ioerr.github.io/posts/dont-panic/</guid>
        <description>&lt;p&gt;最近在同时阅读四个人的作品，看上去风马牛不相及，但又有内在的关联：&lt;/p&gt;

&lt;p&gt;阮一峰的《未来世界的幸存者》；&lt;br /&gt;
卡钦斯基（Theodore Kaczynski）的长文《论工业社会及其未来》；&lt;br /&gt;
冯象的《我是阿尔法》；&lt;br /&gt;
德鲁克（Peter Drucker）的《经济人的末日》、《工业人的未来》、《公司的概念》、《新社会》等等。&lt;/p&gt;

&lt;p&gt;他们的共同点是认识到科学技术——计算机、互联网、人工智能、大数据、基因编辑…任何资本主义大规模工业生产活动及其成果——已经和将会对人类社会产生前所未有冲击，重构、颠覆人类社会，乃至经过自然演化发展到今天的人类这种生物。&lt;/p&gt;

&lt;p&gt;不同点在于，他们想到的应对解决方案可谓完全不同。&lt;/p&gt;

&lt;p&gt;阮一峰的建议主要在个人层面，如加强个人的学习教育投入，鼓励创业创新，做好职业和人生规划，争取成为未来的高级人类那一小拨。&lt;br /&gt;
但在宏观层面没有什么想法。他表达了和卡钦斯基一样的担忧，认为技术发展可能会导致人类社会脆弱和丧失自由，但也只能沿着看不清楚的技术之路继续走下去。&lt;/p&gt;

&lt;p&gt;卡钦斯基的文章则直言工业社会的未来只可能是被体系奴役或全面崩溃，工业社会的体系要么被一小群精英掌握，要么人类彻底依赖于机器，个人要么因为工业社会造成的严重的心理和生理问题被淘汰掉，要么被体系当作无用的个体清除掉，要么丧失自由成为体系的奴隶。当体系持续运转时，个体承受的痛苦超过之前的社会体系，而当体系无法持续运转时，整个社会将会崩溃并倒退回工业时代之前的野蛮战争状态。&lt;br /&gt;
他给出的方案和实际执行的行动是，在来得及退出工业社会的死胡同之时，放弃依赖大规模社会组织的技术发展，为之不惜采用暴力恐怖袭击。&lt;/p&gt;

&lt;p&gt;冯象认为资本主义社会无法解决贫富差距扩大、技术进步带来的大失业、福利制度无以为继、生产依赖机器、大企业全面支配控制个人等问题，于是从人工智能和法学的关系切入，认为未来人工智能将作为政府监管社会的强力工具，介入处理人类的法律事务，并将私法问题转化为公法问题，将市场经济转化为计划经济，最终干预人类的政治活动，成为超越人类之上的更高智慧。它可能带来生产力的大飞跃，可能圈养或灭绝人类，也有可能在私有制度下被私人企业用于违法活动、寡头垄断和战争，走上失控之路。&lt;br /&gt;
他给出的药方是，不允许个人和私人企业发展、维护人工智能技术，收归国有，发展到高级阶段则经济全面公有化，国家统一监督计划人工智能的应用。以及，在资本主义制度下，发展到机器人消灭劳动分工，带来大失业，使全人类一律变成机器的附属品，私人财富没有意义时，顺理成章地取消私有制度，走向共产主义。同时，向演化出自我意识的机器人灌输为人民服务的先进性思想和“毫不利己，专门利人”的共产主义道德，让它承担起爱护人类的积极义务，与人类和谐共处，最终实现共产主义。&lt;/p&gt;

&lt;p&gt;德鲁克的几本书而且写作出版的年代最久远，但其深度和广度乃至洞察力却是上述三人的文章不可比拟的。&lt;br /&gt;
他在计算机和人工智能大规模应用之前就认识到了大规模工业生产对人类社会的影响，既没有被法西斯和极权主义的组织概念蒙骗，也不像卡钦斯基那样对工业社会的未来悲观绝望，更不像乌托邦信徒一样为了追求理念中的自由而选择抽掉经济基础的激进手段。&lt;br /&gt;
在德鲁克看来，工业人的身份、企业作为社会组织的功能和责任、社会的全新秩序是工业社会继续发展必须要重新界定和整合的。而且这一过程直到今天依然还在继续，这一人类历史上最深远的社会转型带来的阵痛不应该是因噎废食或病急乱投医的理由。&lt;/p&gt;

&lt;p&gt;虽然我还没有全部读完德鲁克的这几本书，但他对大企业和工业社会弊病症结的精彩分析，对社会组织结构彻底变革的乐观，对人的自由、尊严、想象力和创造力的尊重和信心，贯穿始终，没有焦虑和恐慌，积极面对未来的问题，这种阅读的感觉很好。&lt;br /&gt;
等到全部读完了，再来一篇总结吧。&lt;/p&gt;

&lt;p&gt;话说回来，尽管上述几个作者写作的初衷之一是担忧人类被机器人取代，但也许这事其实并没那么可怕，完全不用恐慌。&lt;br /&gt;
现实当中许多人根本不在乎自己和其他人被自己的同类奴役、豢养、牺牲和屠杀，换成让未来机器人干这个事情，也许他们还要为机器人的高效率而欢欣鼓舞呢。&lt;/p&gt;

&lt;p&gt;2023-06-11 更新：&lt;/p&gt;

&lt;p&gt;邮寄炸弹杀死3人、伤23人的卡钦斯基昨天在监狱去世。他在1995年发表了《&lt;a href=&#34;https://z.arlmy.me/Wiki/library/Original_Kaczynski_IndustrialSocietyAndItsFuture.html&#34;&gt;论工业社会及其未来&lt;/a&gt;》阐述理念。&lt;br /&gt;
除了《Industrial Society and Its Future》外，另有两本出版物《Technological Slavery》和《Anti-Tech Revolution: Why and How》。&lt;/p&gt;

&lt;p&gt;在我看来，他属于那种虽然很聪明，有深度思考，但意识不到思考的结果不对劲的人。&lt;br /&gt;
如果一个普通人发现结论不正常，比如反人类、反社会，会反思哪里出错了，但他对自己的才智和思考逻辑笃信不移，无论得出什么结论，都只会认为是别人没有先见之明，不理解他的预言，因此不惜犯罪杀人来践行自己的理念。&lt;/p&gt;
</description>
      </item>
    
      <item>
        <title>我为什么反对卢德主义</title>
        <link>https://ioerr.github.io/posts/wo-weishenme-fandui-luddism/</link>
        <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
        <author>
            <name>Calon</name>
            <uri>https://twitter.com/calon</uri>
            <email>calon.xu@gmail.com</email>
        </author>
        <guid>https://ioerr.github.io/posts/wo-weishenme-fandui-luddism/</guid>
        <description>&lt;p&gt;工业革命初期，失业的工人认为他们被机器抢走了工作机会，于是捣毁机器，他们被称为卢德主义者。&lt;/p&gt;

&lt;p&gt;随着工业革命继续进行，人们认识到机器取代低效的人力不可避免，卢德主义慢慢不再有号召力。&lt;/p&gt;

&lt;p&gt;到了计算机时代，新的卢德主义者们担忧计算机和人工智能会胜过和取代人类，许多科学家和计算机业界的知名人士也呼吁停止人工智能发展。&lt;/p&gt;

&lt;p&gt;我可以理解卢德主义者担忧技术快速发展带来的结构性失业问题，但不认为停止技术发展是解决该问题的好办法——无论从历史经验还是经济学理论来看，卢德主义都找错了问题的原因，表面看是技术带来的问题，归根结底还是经济和政治问题，其解决方案因此也站不住脚。&lt;/p&gt;

&lt;p&gt;我也认同未来的强人工智能的确有胜过、取代、奴役和消灭人类的危险，但从价值观出发，我强烈反感卢德主义——因为卢德主义代表最反对人类价值的观点。&lt;/p&gt;

&lt;p&gt;生命的价值和尊严在于生存本身，还是其创造的价值？&lt;br /&gt;
你是根据一个人生存状况还是他创造的东西来评价他？&lt;br /&gt;
这就是技术发展问题背后的价值观差异。&lt;/p&gt;

&lt;p&gt;在我看来，人类之所以为人类，区别于其他已知的生物，是因为人类会为了生存繁衍之上的理想和目标运用理性思考和技术工具，不断有目的、有意识地发明创造和改变世界，而不只是为了在残酷的环境中苟且偷生。&lt;/p&gt;

&lt;p&gt;如果人类没有超越世界给定的追求目标，那么无论生活如何富足舒适，和无智慧的生物又有什么本质区别？&lt;/p&gt;

&lt;p&gt;人工智能等计算机技术的发展，既是大幅度提升技术工具的生产力，也是对人类自身智慧机理的深入探索方式之一，更是突破自然界演化结果的尝试和挑战：突破碳基生命智慧上限，甚至与人工智慧并存形成新形态的生命形式。&lt;/p&gt;

&lt;p&gt;计算机时代的新卢德主义，则是在“人类的安全”和“人类成为更高维度智慧生命”之间，坚定认为为了前者的缘故，必须牺牲后者的机会——即使技术的发展未必就会毁灭人类，人类社会的问题也未必来自于技术发展，更不用说未来也许只有依靠新技术才能应对星球级别的天灾。&lt;/p&gt;

&lt;p&gt;曾经的地壳霸主恐龙统治地球表面超过1亿6千万年，人类站到食物链顶端的时间还差得远，但如果坚持卢德主义，失去技术发展带来的无限可能，那么人类的未来与恐龙将没有区别。&lt;/p&gt;

&lt;p&gt;另：最近看到冯象的《我是阿尔法》和阮一峰的《未来世界的幸存者》都表达了对机器取代人类的担忧，以及为了避免这种结局而停止技术发展的倾向。&lt;br /&gt;
这方面最值得说道的应该是 Kaczynski 的《工业社会及其未来》，事迹影响大，中文读者相对比较熟悉，一些对未来技术发展的思考可以引出不少有意思的话题，后续可以写个系列出来。&lt;/p&gt;
</description>
      </item>
    
  </channel>
</rss>
