<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>安全 on 读写错误</title>
    <link>https://ioerr.github.io/tags/%E5%AE%89%E5%85%A8/</link>
    <description>Recent content in 安全 on 读写错误</description>
    <generator>Hugo -- 0.126.0</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 09 Dec 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://ioerr.github.io/tags/%E5%AE%89%E5%85%A8/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>己不自重，而望人重之，岂不怪哉？</title>
      <link>https://ioerr.github.io/posts/ji-bu-zizhong-er-wang-ren-zhongzhi-qibu-guaizai/</link>
      <pubDate>Tue, 09 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/ji-bu-zizhong-er-wang-ren-zhongzhi-qibu-guaizai/</guid>
      <description>看到一位参与开发豆包 AI 手机助手的人聊他的想法（按我的习惯是要给出文章链接，但现在自媒体的文章对互联网太不友好，又是图片又是强制手机登录，那我</description>
      <content:encoded><![CDATA[<p>看到一位参与开发豆包 AI 手机助手的人聊他的想法（按我的习惯是要给出文章链接，但现在自媒体的文章对互联网太不友好，又是图片又是强制手机登录，那我就不给链接了，你选的嘛），关于隐私安全的部分：</p>
<blockquote>
<p>如果我们抛开隐私安全和三方应用限制，你可以想象下AI给你提供的帮助是会多么精准和高效吗？<br>
目前绝大多数普通用户的态度会有抵触甚至是恐惧，我凭什么把我如此多的信息交给你？<br>
我感觉这个问题其实没有那么可怕和难解，只要把模型能力和交互做的足够牛逼就可以了。 当AI手机系统带来的收益远远超过了你对隐私性的顾虑，它的能力达到一个临界值，一定有会尝鲜者使用并且不遗余力的宣传他的好处，辐射的人会越来越多，让你的好奇心战胜你对它的顾虑。<br>
字节深知这点的重要性，我相信他们会非常认真的对待数据隐私相关的事情，会有很多的工作围绕这个展开。我觉得这是可以解的问题。</p>
</blockquote>
<p>总结起来是两点：</p>
<ol>
<li>只要足够好用到超过对隐私安全的顾虑就行；</li>
<li>要相信字节跳动会解决隐私安全问题。</li>
</ol>
<p>从第1点表现出的态度和字节跳动当前的行为，我是没法相信第2点。<br>
就好像有人说，只要钱给得够多，就不用担心低效加班和过劳死的问题，自然会有人愿意拿钱卖命。同时又说，放心，我们会充分考虑你的健康问题。</p>
<p>我觉得，如果一个人自己都不重视自己的生命、健康、财产、隐私或其他权利，有何资格轻易相信别人会重视和保护它们？真以为自己和对方情同父子吗？</p>
]]></content:encoded>
    </item>
    <item>
      <title>恐惧和匮乏养成的文明观</title>
      <link>https://ioerr.github.io/posts/kongju-he-kuifa-yangcheng-de-wenmingguan/</link>
      <pubDate>Thu, 04 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/kongju-he-kuifa-yangcheng-de-wenmingguan/</guid>
      <description>感觉很多人在长期恐惧和匮乏的环境中形成的价值观甚至是严重的心理疾病，已经很难再改变或修复了，只有等新一代在不那么恐惧和匮乏的环境中成长之后，</description>
      <content:encoded><![CDATA[<p>感觉很多人在长期恐惧和匮乏的环境中形成的价值观甚至是严重的心理疾病，已经很难再改变或修复了，只有等新一代在不那么恐惧和匮乏的环境中成长之后，才能改善在人群中的占比。</p>
<p>他们对文明的理解是这样的：<br>
仓禀实而知礼节，所以我们先要有钱，把别人的钱都抢过来，就自然会发展出文明了。<br>
现在讲文明的人，祖上都是当过强盗的，所以抢劫是文明的前置、必要条件。<br>
你没有体会过穷到吃不饱饭的感觉，快饿死了当然不得不去抢劫，你说不要抢劫就是站着说话不腰疼，何不食肉糜。</p>
<p>看到<a href="https://utopia.cool/@incognito/115142921159531352">象友发的</a>（有做精简改动）：</p>
<blockquote>
<p>法国人价值观里的fraternité这个词一般被翻译成“博爱”。这个词带有宗教色彩，上帝说，要爱你的邻人。<br>
很多法国人真的信这个，这并不是一种虚伪和圣母，而是这种民族价值观强调的是人类层面上的互助。很多人发自内心地相信，当你落难了，我需要给予你人道主义的帮助，所以灾难降临到我头上，我也会得到救助。<br>
中国人不信这个，就是因为我们早就意识到了没有人会来帮助我们，一切都要靠我们自己。我们这一代人，完全不相信人与人之间的互助，毫无安全感。</p>
</blockquote>
<p>再补充一个，就是不相信人可能会对其他人有无条件的善意和同理心。</p>
<p>如果感受不到他人的善意，会说“社会本就冷漠无情”；<br>
发现有人超出了刻板认知，就会说“这都是虚伪的圣母”，甚至期待他们被辜负和伤害；<br>
而看到反面的恶人恶行后，则终于安心：“这个世界果然是我认识的那样”；<br>
于是循环往复，不断强化这种认知，永远也跳不出来。</p>
]]></content:encoded>
    </item>
    <item>
      <title>一纸禁令的逻辑</title>
      <link>https://ioerr.github.io/posts/yizhi-jinling-de-luoji/</link>
      <pubDate>Tue, 12 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/yizhi-jinling-de-luoji/</guid>
      <description>11月11日，珠海发生驾车冲撞致多人伤亡的重大恶性案件。 网友们讨论时就畅想会不会禁车：智能驾驶系统一旦普及，谁也不能操控汽车去撞人了。 虽然可</description>
      <content:encoded><![CDATA[<p>11月11日，珠海发生驾车冲撞致多人伤亡的重大恶性案件。<br>
网友们讨论时就畅想会不会禁车：<a href="https://x.com/paulagent/status/1857119031792210276">智能驾驶系统一旦普及，谁也不能操控汽车去撞人了</a>。<br>
虽然可能性不大，但按照喜欢动不动一纸禁令的逻辑，真要禁止好像也无力阻止。</p>
<p>比如，现在有巨大的自驾出行需求，如果禁止开车上路，影响必然很大。<br>
如果自动驾驶技术成熟了呢？<br>
一切纳入统一管理，服从统一调度，是不是禁止私家车私自上路就有条件了？</p>
<p>到那个时候，你想要反对禁止私家车，可能就要面对这样的质问：<br>
有了统一提供的人人共享的自动驾驶汽车，你为什么还要自己开车、骑车、走路出门呢？<br>
你知道这种极端自私的行为会给公共道路引入多少不可控因素，给自动驾驶指挥中心带来多少额外计算开销吗？<br>
保留这些非标准的交通工具，你是有脱离控制伺机伤人的想法吗？<br>
是想给好不容易创造的最安全环境抹黑拆台吗？</p>
<p><a href="https://x.com/005c006e/status/1857162693293048025">还有网友说</a>，这思路往下走，想不违反物理定律只能降低个人能处置的能量量级。<br>
车不让动，油能加吧？电池总不能每次出门审批通过才给装吧？<br>
停车场一电钻下去一样能释放能量嘛。<br>
不过这个思路确实可以继续，到时候发出声波前都要先报AI审批，那确实很难有力气整大KD，也算达到目的，而过去也算实践过可以说经验丰富。</p>
<p>等到以后变成少数脑细胞指挥多数身体细胞的有机体了，为了保证安全，未经允许擅自说话和行动的细胞都得清除掉。</p>
]]></content:encoded>
    </item>
    <item>
      <title>杞人忧天</title>
      <link>https://ioerr.github.io/posts/qiren-youtian/</link>
      <pubDate>Sun, 29 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/qiren-youtian/</guid>
      <description>ZoomQuiet： AI 安全和以往最大的不同在, 这种安全留给人类反应的时间越来越短, 不像 DDT 时代,我们用20年发现有问题, 用10年修正, 整个儿生</description>
      <content:encoded><![CDATA[<p><a href="https://x.com/zoomq/status/1840237734071607371">ZoomQuiet</a>：<br>
AI 安全和以往最大的不同在,<br>
这种安全留给人类反应的时间越来越短,<br>
不像 DDT 时代,我们用20年发现有问题, 用10年修正,<br>
整个儿生态并没崩溃;<br>
而 AI 的安全问题可能, 几百亳秒后, 超级智能诞生,<br>
因为最初一行道德代码中一个标点错误,<br>
人类就消失了,我们一点儿改善/修订的机会都没有&hellip;</p>
<p><a href="https://x.com/calon/status/1840252252650623154">Calon</a>：<br>
我目前仍然觉得这是杞人忧天。<br>
超级智能诞生，和超级智能能够认识、理解、改造和掌握现实世界，中间还有巨大的鸿沟。</p>
<p>对超级智能的担忧某种程度上是人类对自身能力自负的投射和放大。<br>
虽然人类会认为自己的智能会赶不上超级人工智能，看上去是谦虚、自卑，但实际上也可能是认为自己凭借智能优势已经成为万物之灵、世界的主宰。<br>
如果出现一个比自己更智慧的存在，那可不得了，一定会是新的霸主，而且会无法克服并继承和放大自己的贪婪、残忍、极端…这个新的霸主一定能够凭借智慧突破认知瓶颈，无往而不利，直接飞升成仙都不为过。</p>
<p>人类以为自己在这个境界的临门处徘徊着，只要超越自己就行了。<br>
也许实际上还差得远呢——即使是超越了人类的超级智能，也只是鸭立鸡群的程度而已。</p>
]]></content:encoded>
    </item>
    <item>
      <title>双密码</title>
      <link>https://ioerr.github.io/posts/shuang-mima/</link>
      <pubDate>Fri, 13 May 2011 02:54:08 +0000</pubDate>
      <guid>https://ioerr.github.io/posts/shuang-mima/</guid>
      <description>Flickr、Tumblr、Evernote、Friendfeed 等服务的发布用邮箱地址都是随机的，如果用户不满意，需要自己不断刷新直到随机</description>
      <content:encoded><![CDATA[<p>Flickr、Tumblr、Evernote、Friendfeed<br>
等服务的发布用邮箱地址都是随机的，如果用户不满意，需要自己不断刷新直到随机刷出来一个比较好记好看的地址。</p>
<p>与此相反，Blogger 的 Mail2Blogger<br>
电子邮箱发布地址是可以自己定义的，只要你想到一个别人猜不出来自己有比较熟悉的字符串就行。<br>
其实这就相当于用户的第二个密码，只是限制在电子邮件应用的范围。</p>
<p>我觉得许多服务都应该有两个密码：<br>
一个密码专门用于管理业务内容或者只发布内容，通常用户只需要用密码登录使用服务，就算临时给朋友当公车号使用也无不可，被盗走了不至于帐号易手；<br>
另一个密码专门用于管理帐户，可以取回第一个密码，可以删除帐号，轻易不动用。</p>
<p>看上去很像 QQ 等服务的密码保护？对，但 QQ<br>
的密码和密码保护机制并不是将业务和帐号的管理完全分离（这也与用户的使用习惯有关），而我认为应用的场景不同、使用的频率不同，对应的密码就应该不同，这样的实现更加简单有效。</p>
<p>补充：<br>
Google<br>
帐号的二次验证功能中，可以设置<a href="https://support.google.com/accounts/answer/185833">应用专用密码</a>，算是比较理想的实现了。</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
