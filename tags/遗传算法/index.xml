<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>遗传算法 on 读写错误</title>
    <link>https://ioerr.github.io/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/</link>
    <description>Recent content in 遗传算法 on 读写错误</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 14 Apr 2023 00:00:00 +0000</lastBuildDate>
    
      <atom:link href="https://ioerr.github.io/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/index.xml" rel="self" type="application/rss+xml" />
    
    
      <item>
        <title>机器人三定律</title>
        <link>https://ioerr.github.io/posts/jiqiren-san-dinglv/</link>
        <pubDate>Fri, 14 Apr 2023 00:00:00 +0000</pubDate>
        <author>
            <name>Calon</name>
            
            
        </author>
        <guid>https://ioerr.github.io/posts/jiqiren-san-dinglv/</guid>
        <description>&lt;p&gt;&lt;a href=&#34;https://twitter.com/mranti/status/1646432557913849856&#34;&gt;Michael Anti&lt;/a&gt;：&lt;/p&gt;

&lt;p&gt;我说，既然自动AI都出来了，机器人三定律是不是要建立了？&lt;br /&gt;
是不是得要求所有AI项目都不得产生伤害人类利益的结果啊？&lt;br /&gt;
这一天天加速的，再不给AI立规矩，我都觉得有点害怕。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/calon/status/1646669486844702720&#34;&gt;Calon&lt;/a&gt;：&lt;/p&gt;

&lt;p&gt;人类自己都搞不清楚什么叫伤害人类利益。&lt;/p&gt;

&lt;p&gt;什么算伤害？而不是保护、警告、教育…&lt;br /&gt;
和你交易赚了钱、雇佣你干活、玩 SM、劝你买加密货币、重金求子、和你一起建设乌托邦、送你去火星或者西伯利亚种土豆，算伤害利益吗？&lt;/p&gt;

&lt;p&gt;什么算人？生理、心理、意识、能力、社会关系…&lt;br /&gt;
植物人、无自主意识的精神病患、刚受精的卵子、坚称自己不是人、只剩下大脑、部分身体替换为机器的是不是人？&lt;/p&gt;

&lt;p&gt;具体的个人和整体的人类是什么关系？&lt;br /&gt;
不同的人类群体和整体的人类又是什么关系？&lt;/p&gt;

&lt;p&gt;人类自己搞明白了吗？&lt;br /&gt;
以其昏昏，使其昭昭。&lt;/p&gt;

&lt;p&gt;人类的原始认知模式不是从概念定义往上构建，不会一开始就抽象出一个叫做“人”的对象，以及相应的方法和规则，然后基于其运行。&lt;br /&gt;
而是从经验中归纳总结，再去检验理论，通过一次次试错知道这个不能干，那个有风险，尝试找到模式和规律。&lt;/p&gt;

&lt;p&gt;所以像阿西莫夫那样直接告诉机器人三定律没什么用，估计得让人类成为 AI 的“自然环境”，淘汰搞不清形势的实例（类似于遗传算法 Genetic Algorithm），留下自己可以悟道的实例。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;机器人三定律：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;第一法则：机器人不得伤害人类，或坐视人类受到伤害；&lt;/p&gt;

&lt;p&gt;第二法则：机器人必须服从人类命令，除非命令与第一法则发生冲突；&lt;/p&gt;

&lt;p&gt;第三法则：在不违背第一或第二法则之下，机器人可以保护自己。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
      </item>
    
  </channel>
</rss>
